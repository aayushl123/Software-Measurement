


<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html id="htmlId">
<head>
  <title>Coverage Report :: KohonenUpdateAction</title>
  <style type="text/css">
    @import "../../.css/coverage.css";
  </style>
</head>

<body>
<div class="header"></div>

<div class="content">
<div class="breadCrumbs">
    [ <a href="../../index.html">all classes</a> ]
    [ <a href="../index.html">org.apache.commons.math4.ml.neuralnet.sofm</a> ]
</div>

<h1>Coverage Summary for Class: KohonenUpdateAction (org.apache.commons.math4.ml.neuralnet.sofm)</h1>

<table class="coverageStats">
<tr>
  <th class="name">Class</th>
<th class="coverageStat 
">
  Class, %
</th>
<th class="coverageStat 
">
  Method, %
</th>
<th class="coverageStat 
">
  Line, %
</th>
</tr>
<tr>
  <td class="name">KohonenUpdateAction</td>
<td class="coverageStat">
  <span class="percent">
    100%
  </span>
  <span class="absValue">
    (1/ 1)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    85.7%
  </span>
  <span class="absValue">
    (6/ 7)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    97.4%
  </span>
  <span class="absValue">
    (38/ 39)
  </span>
</td>
</tr>

</table>

<br/>
<br/>


<div class="sourceCode"><i>1</i>&nbsp;/*
<i>2</i>&nbsp; * Licensed to the Apache Software Foundation (ASF) under one or more
<i>3</i>&nbsp; * contributor license agreements.  See the NOTICE file distributed with
<i>4</i>&nbsp; * this work for additional information regarding copyright ownership.
<i>5</i>&nbsp; * The ASF licenses this file to You under the Apache License, Version 2.0
<i>6</i>&nbsp; * (the &quot;License&quot;); you may not use this file except in compliance with
<i>7</i>&nbsp; * the License.  You may obtain a copy of the License at
<i>8</i>&nbsp; *
<i>9</i>&nbsp; *      http://www.apache.org/licenses/LICENSE-2.0
<i>10</i>&nbsp; *
<i>11</i>&nbsp; * Unless required by applicable law or agreed to in writing, software
<i>12</i>&nbsp; * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
<i>13</i>&nbsp; * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
<i>14</i>&nbsp; * See the License for the specific language governing permissions and
<i>15</i>&nbsp; * limitations under the License.
<i>16</i>&nbsp; */
<i>17</i>&nbsp;
<i>18</i>&nbsp;package org.apache.commons.math4.ml.neuralnet.sofm;
<i>19</i>&nbsp;
<i>20</i>&nbsp;import java.util.Collection;
<i>21</i>&nbsp;import java.util.HashSet;
<i>22</i>&nbsp;import java.util.concurrent.atomic.AtomicLong;
<i>23</i>&nbsp;
<i>24</i>&nbsp;import org.apache.commons.math4.analysis.function.Gaussian;
<i>25</i>&nbsp;import org.apache.commons.math4.linear.ArrayRealVector;
<i>26</i>&nbsp;import org.apache.commons.math4.ml.distance.DistanceMeasure;
<i>27</i>&nbsp;import org.apache.commons.math4.ml.neuralnet.MapUtils;
<i>28</i>&nbsp;import org.apache.commons.math4.ml.neuralnet.Network;
<i>29</i>&nbsp;import org.apache.commons.math4.ml.neuralnet.Neuron;
<i>30</i>&nbsp;import org.apache.commons.math4.ml.neuralnet.UpdateAction;
<i>31</i>&nbsp;
<i>32</i>&nbsp;/**
<i>33</i>&nbsp; * Update formula for &lt;a href=&quot;http://en.wikipedia.org/wiki/Kohonen&quot;&gt;
<i>34</i>&nbsp; * Kohonen&#39;s Self-Organizing Map&lt;/a&gt;.
<i>35</i>&nbsp; * &lt;br&gt;
<i>36</i>&nbsp; * The {@link #update(Network,double[]) update} method modifies the
<i>37</i>&nbsp; * features {@code w} of the &quot;winning&quot; neuron and its neighbours
<i>38</i>&nbsp; * according to the following rule:
<i>39</i>&nbsp; * &lt;code&gt;
<i>40</i>&nbsp; *  w&lt;sub&gt;new&lt;/sub&gt; = w&lt;sub&gt;old&lt;/sub&gt; + &amp;alpha; e&lt;sup&gt;(-d / &amp;sigma;)&lt;/sup&gt; * (sample - w&lt;sub&gt;old&lt;/sub&gt;)
<i>41</i>&nbsp; * &lt;/code&gt;
<i>42</i>&nbsp; * where
<i>43</i>&nbsp; * &lt;ul&gt;
<i>44</i>&nbsp; *  &lt;li&gt;&amp;alpha; is the current &lt;em&gt;learning rate&lt;/em&gt;, &lt;/li&gt;
<i>45</i>&nbsp; *  &lt;li&gt;&amp;sigma; is the current &lt;em&gt;neighbourhood size&lt;/em&gt;, and&lt;/li&gt;
<i>46</i>&nbsp; *  &lt;li&gt;{@code d} is the number of links to traverse in order to reach
<i>47</i>&nbsp; *   the neuron from the winning neuron.&lt;/li&gt;
<i>48</i>&nbsp; * &lt;/ul&gt;
<i>49</i>&nbsp; * &lt;br&gt;
<i>50</i>&nbsp; * This class is thread-safe as long as the arguments passed to the
<i>51</i>&nbsp; * {@link #KohonenUpdateAction(DistanceMeasure,LearningFactorFunction,
<i>52</i>&nbsp; * NeighbourhoodSizeFunction) constructor} are instances of thread-safe
<i>53</i>&nbsp; * classes.
<i>54</i>&nbsp; * &lt;br&gt;
<i>55</i>&nbsp; * Each call to the {@link #update(Network,double[]) update} method
<i>56</i>&nbsp; * will increment the internal counter used to compute the current
<i>57</i>&nbsp; * values for
<i>58</i>&nbsp; * &lt;ul&gt;
<i>59</i>&nbsp; *  &lt;li&gt;the &lt;em&gt;learning rate&lt;/em&gt;, and&lt;/li&gt;
<i>60</i>&nbsp; *  &lt;li&gt;the &lt;em&gt;neighbourhood size&lt;/em&gt;.&lt;/li&gt;
<i>61</i>&nbsp; * &lt;/ul&gt;
<i>62</i>&nbsp; * Consequently, the function instances that compute those values (passed
<i>63</i>&nbsp; * to the constructor of this class) must take into account whether this
<i>64</i>&nbsp; * class&#39;s instance will be shared by multiple threads, as this will impact
<i>65</i>&nbsp; * the training process.
<i>66</i>&nbsp; *
<i>67</i>&nbsp; * @since 3.3
<i>68</i>&nbsp; */
<i>69</i>&nbsp;public class KohonenUpdateAction implements UpdateAction {
<i>70</i>&nbsp;    /** Distance function. */
<i>71</i>&nbsp;    private final DistanceMeasure distance;
<i>72</i>&nbsp;    /** Learning factor update function. */
<i>73</i>&nbsp;    private final LearningFactorFunction learningFactor;
<i>74</i>&nbsp;    /** Neighbourhood size update function. */
<i>75</i>&nbsp;    private final NeighbourhoodSizeFunction neighbourhoodSize;
<i>76</i>&nbsp;    /** Number of calls to {@link #update(Network,double[])}. */
<b class="fc"><i>77</i>&nbsp;    private final AtomicLong numberOfCalls = new AtomicLong(0);</b>
<i>78</i>&nbsp;
<i>79</i>&nbsp;    /**
<i>80</i>&nbsp;     * @param distance Distance function.
<i>81</i>&nbsp;     * @param learningFactor Learning factor update function.
<i>82</i>&nbsp;     * @param neighbourhoodSize Neighbourhood size update function.
<i>83</i>&nbsp;     */
<i>84</i>&nbsp;    public KohonenUpdateAction(DistanceMeasure distance,
<i>85</i>&nbsp;                               LearningFactorFunction learningFactor,
<b class="fc"><i>86</i>&nbsp;                               NeighbourhoodSizeFunction neighbourhoodSize) {</b>
<b class="fc"><i>87</i>&nbsp;        this.distance = distance;</b>
<b class="fc"><i>88</i>&nbsp;        this.learningFactor = learningFactor;</b>
<b class="fc"><i>89</i>&nbsp;        this.neighbourhoodSize = neighbourhoodSize;</b>
<b class="fc"><i>90</i>&nbsp;    }</b>
<i>91</i>&nbsp;
<i>92</i>&nbsp;    /**
<i>93</i>&nbsp;     * {@inheritDoc}
<i>94</i>&nbsp;     */
<i>95</i>&nbsp;    @Override
<i>96</i>&nbsp;    public void update(Network net,
<i>97</i>&nbsp;                       double[] features) {
<b class="fc"><i>98</i>&nbsp;        final long numCalls = numberOfCalls.incrementAndGet() - 1;</b>
<b class="fc"><i>99</i>&nbsp;        final double currentLearning = learningFactor.value(numCalls);</b>
<b class="fc"><i>100</i>&nbsp;        final Neuron best = findAndUpdateBestNeuron(net,</b>
<i>101</i>&nbsp;                                                    features,
<i>102</i>&nbsp;                                                    currentLearning);
<i>103</i>&nbsp;
<b class="fc"><i>104</i>&nbsp;        final int currentNeighbourhood = neighbourhoodSize.value(numCalls);</b>
<i>105</i>&nbsp;        // The farther away the neighbour is from the winning neuron, the
<i>106</i>&nbsp;        // smaller the learning rate will become.
<b class="fc"><i>107</i>&nbsp;        final Gaussian neighbourhoodDecay</b>
<i>108</i>&nbsp;            = new Gaussian(currentLearning,
<i>109</i>&nbsp;                           0,
<i>110</i>&nbsp;                           currentNeighbourhood);
<i>111</i>&nbsp;
<b class="fc"><i>112</i>&nbsp;        if (currentNeighbourhood &gt; 0) {</b>
<i>113</i>&nbsp;            // Initial set of neurons only contains the winning neuron.
<b class="fc"><i>114</i>&nbsp;            Collection&lt;Neuron&gt; neighbours = new HashSet&lt;&gt;();</b>
<b class="fc"><i>115</i>&nbsp;            neighbours.add(best);</b>
<i>116</i>&nbsp;            // Winning neuron must be excluded from the neighbours.
<b class="fc"><i>117</i>&nbsp;            final HashSet&lt;Neuron&gt; exclude = new HashSet&lt;&gt;();</b>
<b class="fc"><i>118</i>&nbsp;            exclude.add(best);</b>
<i>119</i>&nbsp;
<b class="fc"><i>120</i>&nbsp;            int radius = 1;</b>
<i>121</i>&nbsp;            do {
<i>122</i>&nbsp;                // Retrieve immediate neighbours of the current set of neurons.
<b class="fc"><i>123</i>&nbsp;                neighbours = net.getNeighbours(neighbours, exclude);</b>
<i>124</i>&nbsp;
<i>125</i>&nbsp;                // Update all the neighbours.
<b class="fc"><i>126</i>&nbsp;                for (Neuron n : neighbours) {</b>
<b class="fc"><i>127</i>&nbsp;                    updateNeighbouringNeuron(n, features, neighbourhoodDecay.value(radius));</b>
<b class="fc"><i>128</i>&nbsp;                }</b>
<i>129</i>&nbsp;
<i>130</i>&nbsp;                // Add the neighbours to the exclude list so that they will
<i>131</i>&nbsp;                // not be update more than once per training step.
<b class="fc"><i>132</i>&nbsp;                exclude.addAll(neighbours);</b>
<b class="fc"><i>133</i>&nbsp;                ++radius;</b>
<b class="fc"><i>134</i>&nbsp;            } while (radius &lt;= currentNeighbourhood);</b>
<i>135</i>&nbsp;        }
<b class="fc"><i>136</i>&nbsp;    }</b>
<i>137</i>&nbsp;
<i>138</i>&nbsp;    /**
<i>139</i>&nbsp;     * Retrieves the number of calls to the {@link #update(Network,double[]) update}
<i>140</i>&nbsp;     * method.
<i>141</i>&nbsp;     *
<i>142</i>&nbsp;     * @return the current number of calls.
<i>143</i>&nbsp;     */
<i>144</i>&nbsp;    public long getNumberOfCalls() {
<b class="nc"><i>145</i>&nbsp;        return numberOfCalls.get();</b>
<i>146</i>&nbsp;    }
<i>147</i>&nbsp;
<i>148</i>&nbsp;    /**
<i>149</i>&nbsp;     * Tries to update a neuron.
<i>150</i>&nbsp;     *
<i>151</i>&nbsp;     * @param n Neuron to be updated.
<i>152</i>&nbsp;     * @param features Training data.
<i>153</i>&nbsp;     * @param learningRate Learning factor.
<i>154</i>&nbsp;     * @return {@code true} if the update succeeded, {@code true} if a
<i>155</i>&nbsp;     * concurrent update has been detected.
<i>156</i>&nbsp;     */
<i>157</i>&nbsp;    private boolean attemptNeuronUpdate(Neuron n,
<i>158</i>&nbsp;                                        double[] features,
<i>159</i>&nbsp;                                        double learningRate) {
<b class="fc"><i>160</i>&nbsp;        final double[] expect = n.getFeatures();</b>
<b class="fc"><i>161</i>&nbsp;        final double[] update = computeFeatures(expect,</b>
<i>162</i>&nbsp;                                                features,
<i>163</i>&nbsp;                                                learningRate);
<i>164</i>&nbsp;
<b class="fc"><i>165</i>&nbsp;        return n.compareAndSetFeatures(expect, update);</b>
<i>166</i>&nbsp;    }
<i>167</i>&nbsp;
<i>168</i>&nbsp;    /**
<i>169</i>&nbsp;     * Atomically updates the given neuron.
<i>170</i>&nbsp;     *
<i>171</i>&nbsp;     * @param n Neuron to be updated.
<i>172</i>&nbsp;     * @param features Training data.
<i>173</i>&nbsp;     * @param learningRate Learning factor.
<i>174</i>&nbsp;     */
<i>175</i>&nbsp;    private void updateNeighbouringNeuron(Neuron n,
<i>176</i>&nbsp;                                          double[] features,
<i>177</i>&nbsp;                                          double learningRate) {
<i>178</i>&nbsp;        while (true) {
<b class="fc"><i>179</i>&nbsp;            if (attemptNeuronUpdate(n, features, learningRate)) {</b>
<b class="fc"><i>180</i>&nbsp;                break;</b>
<i>181</i>&nbsp;            }
<i>182</i>&nbsp;        }
<b class="fc"><i>183</i>&nbsp;    }</b>
<i>184</i>&nbsp;
<i>185</i>&nbsp;    /**
<i>186</i>&nbsp;     * Searches for the neuron whose features are closest to the given
<i>187</i>&nbsp;     * sample, and atomically updates its features.
<i>188</i>&nbsp;     *
<i>189</i>&nbsp;     * @param net Network.
<i>190</i>&nbsp;     * @param features Sample data.
<i>191</i>&nbsp;     * @param learningRate Current learning factor.
<i>192</i>&nbsp;     * @return the winning neuron.
<i>193</i>&nbsp;     */
<i>194</i>&nbsp;    private Neuron findAndUpdateBestNeuron(Network net,
<i>195</i>&nbsp;                                           double[] features,
<i>196</i>&nbsp;                                           double learningRate) {
<i>197</i>&nbsp;        while (true) {
<b class="fc"><i>198</i>&nbsp;            final Neuron best = MapUtils.findBest(features, net, distance);</b>
<i>199</i>&nbsp;
<b class="fc"><i>200</i>&nbsp;            if (attemptNeuronUpdate(best, features, learningRate)) {</b>
<b class="fc"><i>201</i>&nbsp;                return best;</b>
<i>202</i>&nbsp;            }
<i>203</i>&nbsp;
<i>204</i>&nbsp;            // If another thread modified the state of the winning neuron,
<i>205</i>&nbsp;            // it may not be the best match anymore for the given training
<i>206</i>&nbsp;            // sample: Hence, the winner search is performed again.
<b class="fc"><i>207</i>&nbsp;        }</b>
<i>208</i>&nbsp;    }
<i>209</i>&nbsp;
<i>210</i>&nbsp;    /**
<i>211</i>&nbsp;     * Computes the new value of the features set.
<i>212</i>&nbsp;     *
<i>213</i>&nbsp;     * @param current Current values of the features.
<i>214</i>&nbsp;     * @param sample Training data.
<i>215</i>&nbsp;     * @param learningRate Learning factor.
<i>216</i>&nbsp;     * @return the new values for the features.
<i>217</i>&nbsp;     */
<i>218</i>&nbsp;    private double[] computeFeatures(double[] current,
<i>219</i>&nbsp;                                     double[] sample,
<i>220</i>&nbsp;                                     double learningRate) {
<b class="fc"><i>221</i>&nbsp;        final ArrayRealVector c = new ArrayRealVector(current, false);</b>
<b class="fc"><i>222</i>&nbsp;        final ArrayRealVector s = new ArrayRealVector(sample, false);</b>
<i>223</i>&nbsp;        // c + learningRate * (s - c)
<b class="fc"><i>224</i>&nbsp;        return s.subtract(c).mapMultiplyToSelf(learningRate).add(c).toArray();</b>
<i>225</i>&nbsp;    }
<i>226</i>&nbsp;}
</div>
</div>

<div class="footer">
    
    <div style="float:right;">generated on 2019-06-04 09:26</div>
</div>
</body>
</html>
