


<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html id="htmlId">
<head>
  <title>Coverage Report :: CMAESOptimizer</title>
  <style type="text/css">
    @import "../../.css/coverage.css";
  </style>
</head>

<body>
<div class="header"></div>

<div class="content">
<div class="breadCrumbs">
    [ <a href="../../index.html">all classes</a> ]
    [ <a href="../index.html">org.apache.commons.math4.optim.nonlinear.scalar.noderiv</a> ]
</div>

<h1>Coverage Summary for Class: CMAESOptimizer (org.apache.commons.math4.optim.nonlinear.scalar.noderiv)</h1>

<table class="coverageStats">

<tr>
  <th class="name">Class</th>
<th class="coverageStat 
">
  Method, %
</th>
<th class="coverageStat 
">
  Line, %
</th>
</tr>
<tr>
  <td class="name">CMAESOptimizer</td>
<td class="coverageStat">
  <span class="percent">
    87.8%
  </span>
  <span class="absValue">
    (36/ 41)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    91.5%
  </span>
  <span class="absValue">
    (379/ 414)
  </span>
</td>
</tr>
  <tr>
    <td class="name">CMAESOptimizer$DoubleIndex</td>
<td class="coverageStat">
  <span class="percent">
    60%
  </span>
  <span class="absValue">
    (3/ 5)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    46.2%
  </span>
  <span class="absValue">
    (6/ 13)
  </span>
</td>
  </tr>
  <tr>
    <td class="name">CMAESOptimizer$FitnessFunction</td>
<td class="coverageStat">
  <span class="percent">
    83.3%
  </span>
  <span class="absValue">
    (5/ 6)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    73%
  </span>
  <span class="absValue">
    (27/ 37)
  </span>
</td>
  </tr>
  <tr>
    <td class="name">CMAESOptimizer$PopulationSize</td>
<td class="coverageStat">
  <span class="percent">
    100%
  </span>
  <span class="absValue">
    (2/ 2)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    83.3%
  </span>
  <span class="absValue">
    (5/ 6)
  </span>
</td>
  </tr>
  <tr>
    <td class="name">CMAESOptimizer$Sigma</td>
<td class="coverageStat">
  <span class="percent">
    100%
  </span>
  <span class="absValue">
    (2/ 2)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    100%
  </span>
  <span class="absValue">
    (7/ 7)
  </span>
</td>
  </tr>
  <tr>
    <td class="name">CMAESOptimizer$ValuePenaltyPair</td>
<td class="coverageStat">
  <span class="percent">
    100%
  </span>
  <span class="absValue">
    (2/ 2)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    100%
  </span>
  <span class="absValue">
    (5/ 5)
  </span>
</td>
  </tr>
<tr>
  <td class="name"><strong>total</strong></td>
<td class="coverageStat">
  <span class="percent">
    86.2%
  </span>
  <span class="absValue">
    (50/ 58)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    89%
  </span>
  <span class="absValue">
    (429/ 482)
  </span>
</td>
</tr>
</table>

<br/>
<br/>


<div class="sourceCode"><i>1</i>&nbsp;/*
<i>2</i>&nbsp; * Licensed to the Apache Software Foundation (ASF) under one or more
<i>3</i>&nbsp; * contributor license agreements.  See the NOTICE file distributed with
<i>4</i>&nbsp; * this work for additional information regarding copyright ownership.
<i>5</i>&nbsp; * The ASF licenses this file to You under the Apache License, Version 2.0
<i>6</i>&nbsp; * (the &quot;License&quot;); you may not use this file except in compliance with
<i>7</i>&nbsp; * the License.  You may obtain a copy of the License at
<i>8</i>&nbsp; *
<i>9</i>&nbsp; *      http://www.apache.org/licenses/LICENSE-2.0
<i>10</i>&nbsp; *
<i>11</i>&nbsp; * Unless required by applicable law or agreed to in writing, software
<i>12</i>&nbsp; * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
<i>13</i>&nbsp; * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
<i>14</i>&nbsp; * See the License for the specific language governing permissions and
<i>15</i>&nbsp; * limitations under the License.
<i>16</i>&nbsp; */
<i>17</i>&nbsp;
<i>18</i>&nbsp;package org.apache.commons.math4.optim.nonlinear.scalar.noderiv;
<i>19</i>&nbsp;
<i>20</i>&nbsp;import java.util.ArrayList;
<i>21</i>&nbsp;import java.util.Arrays;
<i>22</i>&nbsp;import java.util.List;
<i>23</i>&nbsp;
<i>24</i>&nbsp;import org.apache.commons.math4.exception.DimensionMismatchException;
<i>25</i>&nbsp;import org.apache.commons.math4.exception.NotPositiveException;
<i>26</i>&nbsp;import org.apache.commons.math4.exception.NotStrictlyPositiveException;
<i>27</i>&nbsp;import org.apache.commons.math4.exception.OutOfRangeException;
<i>28</i>&nbsp;import org.apache.commons.math4.exception.TooManyEvaluationsException;
<i>29</i>&nbsp;import org.apache.commons.math4.linear.Array2DRowRealMatrix;
<i>30</i>&nbsp;import org.apache.commons.math4.linear.EigenDecomposition;
<i>31</i>&nbsp;import org.apache.commons.math4.linear.MatrixUtils;
<i>32</i>&nbsp;import org.apache.commons.math4.linear.RealMatrix;
<i>33</i>&nbsp;import org.apache.commons.math4.optim.ConvergenceChecker;
<i>34</i>&nbsp;import org.apache.commons.math4.optim.OptimizationData;
<i>35</i>&nbsp;import org.apache.commons.math4.optim.PointValuePair;
<i>36</i>&nbsp;import org.apache.commons.math4.optim.nonlinear.scalar.GoalType;
<i>37</i>&nbsp;import org.apache.commons.math4.optim.nonlinear.scalar.MultivariateOptimizer;
<i>38</i>&nbsp;import org.apache.commons.rng.UniformRandomProvider;
<i>39</i>&nbsp;import org.apache.commons.statistics.distribution.ContinuousDistribution;
<i>40</i>&nbsp;import org.apache.commons.statistics.distribution.NormalDistribution;
<i>41</i>&nbsp;import org.apache.commons.math4.util.FastMath;
<i>42</i>&nbsp;import org.apache.commons.math4.util.MathArrays;
<i>43</i>&nbsp;
<i>44</i>&nbsp;/**
<i>45</i>&nbsp; * An implementation of the active Covariance Matrix Adaptation Evolution Strategy (CMA-ES)
<i>46</i>&nbsp; * for non-linear, non-convex, non-smooth, global function minimization.
<i>47</i>&nbsp; * &lt;p&gt;
<i>48</i>&nbsp; * The CMA-Evolution Strategy (CMA-ES) is a reliable stochastic optimization method
<i>49</i>&nbsp; * which should be applied if derivative-based methods, e.g. quasi-Newton BFGS or
<i>50</i>&nbsp; * conjugate gradient, fail due to a rugged search landscape (e.g. noise, local
<i>51</i>&nbsp; * optima, outlier, etc.) of the objective function. Like a
<i>52</i>&nbsp; * quasi-Newton method, the CMA-ES learns and applies a variable metric
<i>53</i>&nbsp; * on the underlying search space. Unlike a quasi-Newton method, the
<i>54</i>&nbsp; * CMA-ES neither estimates nor uses gradients, making it considerably more
<i>55</i>&nbsp; * reliable in terms of finding a good, or even close to optimal, solution.
<i>56</i>&nbsp; * &lt;p&gt;
<i>57</i>&nbsp; * In general, on smooth objective functions the CMA-ES is roughly ten times
<i>58</i>&nbsp; * slower than BFGS (counting objective function evaluations, no gradients provided).
<i>59</i>&nbsp; * For up to &lt;code&gt;N=10&lt;/code&gt; variables also the derivative-free simplex
<i>60</i>&nbsp; * direct search method (Nelder and Mead) can be faster, but it is
<i>61</i>&nbsp; * far less reliable than CMA-ES.
<i>62</i>&nbsp; * &lt;p&gt;
<i>63</i>&nbsp; * The CMA-ES is particularly well suited for non-separable
<i>64</i>&nbsp; * and/or badly conditioned problems. To observe the advantage of CMA compared
<i>65</i>&nbsp; * to a conventional evolution strategy, it will usually take about
<i>66</i>&nbsp; * &lt;code&gt;30 N&lt;/code&gt; function evaluations. On difficult problems the complete
<i>67</i>&nbsp; * optimization (a single run) is expected to take &lt;em&gt;roughly&lt;/em&gt; between
<i>68</i>&nbsp; * &lt;code&gt;30 N&lt;/code&gt; and &lt;code&gt;300 N&lt;sup&gt;2&lt;/sup&gt;&lt;/code&gt;
<i>69</i>&nbsp; * function evaluations.
<i>70</i>&nbsp; * &lt;p&gt;
<i>71</i>&nbsp; * This implementation is translated and adapted from the Matlab version
<i>72</i>&nbsp; * of the CMA-ES algorithm as implemented in module {@code cmaes.m} version 3.51.
<i>73</i>&nbsp; * &lt;p&gt;
<i>74</i>&nbsp; * For more information, please refer to the following links:
<i>75</i>&nbsp; * &lt;ul&gt;
<i>76</i>&nbsp; *  &lt;li&gt;&lt;a href=&quot;http://www.lri.fr/~hansen/cmaes.m&quot;&gt;Matlab code&lt;/a&gt;&lt;/li&gt;
<i>77</i>&nbsp; *  &lt;li&gt;&lt;a href=&quot;http://www.lri.fr/~hansen/cmaesintro.html&quot;&gt;Introduction to CMA-ES&lt;/a&gt;&lt;/li&gt;
<i>78</i>&nbsp; *  &lt;li&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/CMA-ES&quot;&gt;Wikipedia&lt;/a&gt;&lt;/li&gt;
<i>79</i>&nbsp; * &lt;/ul&gt;
<i>80</i>&nbsp; *
<i>81</i>&nbsp; * @since 3.0
<i>82</i>&nbsp; */
<b class="fc"><i>83</i>&nbsp;public class CMAESOptimizer</b>
<i>84</i>&nbsp;    extends MultivariateOptimizer {
<i>85</i>&nbsp;    // global search parameters
<i>86</i>&nbsp;    /**
<i>87</i>&nbsp;     * Population size, offspring number. The primary strategy parameter to play
<i>88</i>&nbsp;     * with, which can be increased from its default value. Increasing the
<i>89</i>&nbsp;     * population size improves global search properties in exchange to speed.
<i>90</i>&nbsp;     * Speed decreases, as a rule, at most linearly with increasing population
<i>91</i>&nbsp;     * size. It is advisable to begin with the default small population size.
<i>92</i>&nbsp;     */
<i>93</i>&nbsp;    private int lambda; // population size
<i>94</i>&nbsp;    /**
<i>95</i>&nbsp;     * Covariance update mechanism, default is active CMA. isActiveCMA = true
<i>96</i>&nbsp;     * turns on &quot;active CMA&quot; with a negative update of the covariance matrix and
<i>97</i>&nbsp;     * checks for positive definiteness. OPTS.CMA.active = 2 does not check for
<i>98</i>&nbsp;     * pos. def. and is numerically faster. Active CMA usually speeds up the
<i>99</i>&nbsp;     * adaptation.
<i>100</i>&nbsp;     */
<i>101</i>&nbsp;    private final boolean isActiveCMA;
<i>102</i>&nbsp;    /**
<i>103</i>&nbsp;     * Determines how often a new random offspring is generated in case it is
<i>104</i>&nbsp;     * not feasible / beyond the defined limits, default is 0.
<i>105</i>&nbsp;     */
<i>106</i>&nbsp;    private final int checkFeasableCount;
<i>107</i>&nbsp;    /**
<i>108</i>&nbsp;     * @see Sigma
<i>109</i>&nbsp;     */
<i>110</i>&nbsp;    private double[] inputSigma;
<i>111</i>&nbsp;    /** Number of objective variables/problem dimension */
<i>112</i>&nbsp;    private int dimension;
<i>113</i>&nbsp;    /**
<i>114</i>&nbsp;     * Defines the number of initial iterations, where the covariance matrix
<i>115</i>&nbsp;     * remains diagonal and the algorithm has internally linear time complexity.
<i>116</i>&nbsp;     * diagonalOnly = 1 means keeping the covariance matrix always diagonal and
<i>117</i>&nbsp;     * this setting also exhibits linear space complexity. This can be
<i>118</i>&nbsp;     * particularly useful for dimension &gt; 100.
<i>119</i>&nbsp;     * @see &lt;a href=&quot;http://hal.archives-ouvertes.fr/inria-00287367/en&quot;&gt;A Simple Modification in CMA-ES&lt;/a&gt;
<i>120</i>&nbsp;     */
<i>121</i>&nbsp;    private int diagonalOnly;
<i>122</i>&nbsp;    /** Number of objective variables/problem dimension */
<b class="fc"><i>123</i>&nbsp;    private boolean isMinimize = true;</b>
<i>124</i>&nbsp;    /** Indicates whether statistic data is collected. */
<i>125</i>&nbsp;    private final boolean generateStatistics;
<i>126</i>&nbsp;
<i>127</i>&nbsp;    // termination criteria
<i>128</i>&nbsp;    /** Maximal number of iterations allowed. */
<i>129</i>&nbsp;    private final int maxIterations;
<i>130</i>&nbsp;    /** Limit for fitness value. */
<i>131</i>&nbsp;    private final double stopFitness;
<i>132</i>&nbsp;    /** Stop if x-changes larger stopTolUpX. */
<i>133</i>&nbsp;    private double stopTolUpX;
<i>134</i>&nbsp;    /** Stop if x-change smaller stopTolX. */
<i>135</i>&nbsp;    private double stopTolX;
<i>136</i>&nbsp;    /** Stop if fun-changes smaller stopTolFun. */
<i>137</i>&nbsp;    private double stopTolFun;
<i>138</i>&nbsp;    /** Stop if back fun-changes smaller stopTolHistFun. */
<i>139</i>&nbsp;    private double stopTolHistFun;
<i>140</i>&nbsp;
<i>141</i>&nbsp;    // selection strategy parameters
<i>142</i>&nbsp;    /** Number of parents/points for recombination. */
<i>143</i>&nbsp;    private int mu; //
<i>144</i>&nbsp;    /** log(mu + 0.5), stored for efficiency. */
<i>145</i>&nbsp;    private double logMu2;
<i>146</i>&nbsp;    /** Array for weighted recombination. */
<i>147</i>&nbsp;    private RealMatrix weights;
<i>148</i>&nbsp;    /** Variance-effectiveness of sum w_i x_i. */
<i>149</i>&nbsp;    private double mueff; //
<i>150</i>&nbsp;
<i>151</i>&nbsp;    // dynamic strategy parameters and constants
<i>152</i>&nbsp;    /** Overall standard deviation - search volume. */
<i>153</i>&nbsp;    private double sigma;
<i>154</i>&nbsp;    /** Cumulation constant. */
<i>155</i>&nbsp;    private double cc;
<i>156</i>&nbsp;    /** Cumulation constant for step-size. */
<i>157</i>&nbsp;    private double cs;
<i>158</i>&nbsp;    /** Damping for step-size. */
<i>159</i>&nbsp;    private double damps;
<i>160</i>&nbsp;    /** Learning rate for rank-one update. */
<i>161</i>&nbsp;    private double ccov1;
<i>162</i>&nbsp;    /** Learning rate for rank-mu update&#39; */
<i>163</i>&nbsp;    private double ccovmu;
<i>164</i>&nbsp;    /** Expectation of ||N(0,I)|| == norm(randn(N,1)). */
<i>165</i>&nbsp;    private double chiN;
<i>166</i>&nbsp;    /** Learning rate for rank-one update - diagonalOnly */
<i>167</i>&nbsp;    private double ccov1Sep;
<i>168</i>&nbsp;    /** Learning rate for rank-mu update - diagonalOnly */
<i>169</i>&nbsp;    private double ccovmuSep;
<i>170</i>&nbsp;
<i>171</i>&nbsp;    // CMA internal values - updated each generation
<i>172</i>&nbsp;    /** Objective variables. */
<i>173</i>&nbsp;    private RealMatrix xmean;
<i>174</i>&nbsp;    /** Evolution path. */
<i>175</i>&nbsp;    private RealMatrix pc;
<i>176</i>&nbsp;    /** Evolution path for sigma. */
<i>177</i>&nbsp;    private RealMatrix ps;
<i>178</i>&nbsp;    /** Norm of ps, stored for efficiency. */
<i>179</i>&nbsp;    private double normps;
<i>180</i>&nbsp;    /** Coordinate system. */
<i>181</i>&nbsp;    private RealMatrix B;
<i>182</i>&nbsp;    /** Scaling. */
<i>183</i>&nbsp;    private RealMatrix D;
<i>184</i>&nbsp;    /** B*D, stored for efficiency. */
<i>185</i>&nbsp;    private RealMatrix BD;
<i>186</i>&nbsp;    /** Diagonal of sqrt(D), stored for efficiency. */
<i>187</i>&nbsp;    private RealMatrix diagD;
<i>188</i>&nbsp;    /** Covariance matrix. */
<i>189</i>&nbsp;    private RealMatrix C;
<i>190</i>&nbsp;    /** Diagonal of C, used for diagonalOnly. */
<i>191</i>&nbsp;    private RealMatrix diagC;
<i>192</i>&nbsp;    /** Number of iterations already performed. */
<i>193</i>&nbsp;    private int iterations;
<i>194</i>&nbsp;
<i>195</i>&nbsp;    /** History queue of best values. */
<i>196</i>&nbsp;    private double[] fitnessHistory;
<i>197</i>&nbsp;    /** Size of history queue of best values. */
<i>198</i>&nbsp;    private int historySize;
<i>199</i>&nbsp;
<i>200</i>&nbsp;    /** Gaussian sampler. */
<i>201</i>&nbsp;    private final ContinuousDistribution.Sampler random;
<i>202</i>&nbsp;
<i>203</i>&nbsp;    /** History of sigma values. */
<b class="fc"><i>204</i>&nbsp;    private final List&lt;Double&gt; statisticsSigmaHistory = new ArrayList&lt;&gt;();</b>
<i>205</i>&nbsp;    /** History of mean matrix. */
<b class="fc"><i>206</i>&nbsp;    private final List&lt;RealMatrix&gt; statisticsMeanHistory = new ArrayList&lt;&gt;();</b>
<i>207</i>&nbsp;    /** History of fitness values. */
<b class="fc"><i>208</i>&nbsp;    private final List&lt;Double&gt; statisticsFitnessHistory = new ArrayList&lt;&gt;();</b>
<i>209</i>&nbsp;    /** History of D matrix. */
<b class="fc"><i>210</i>&nbsp;    private final List&lt;RealMatrix&gt; statisticsDHistory = new ArrayList&lt;&gt;();</b>
<i>211</i>&nbsp;
<i>212</i>&nbsp;    /**
<i>213</i>&nbsp;     * @param maxIterations Maximal number of iterations.
<i>214</i>&nbsp;     * @param stopFitness Whether to stop if objective function value is smaller than
<i>215</i>&nbsp;     * {@code stopFitness}.
<i>216</i>&nbsp;     * @param isActiveCMA Chooses the covariance matrix update method.
<i>217</i>&nbsp;     * @param diagonalOnly Number of initial iterations, where the covariance matrix
<i>218</i>&nbsp;     * remains diagonal.
<i>219</i>&nbsp;     * @param checkFeasableCount Determines how often new random objective variables are
<i>220</i>&nbsp;     * generated in case they are out of bounds.
<i>221</i>&nbsp;     * @param rng Random generator.
<i>222</i>&nbsp;     * @param generateStatistics Whether statistic data is collected.
<i>223</i>&nbsp;     * @param checker Convergence checker.
<i>224</i>&nbsp;     *
<i>225</i>&nbsp;     * @since 3.1
<i>226</i>&nbsp;     */
<i>227</i>&nbsp;    public CMAESOptimizer(int maxIterations,
<i>228</i>&nbsp;                          double stopFitness,
<i>229</i>&nbsp;                          boolean isActiveCMA,
<i>230</i>&nbsp;                          int diagonalOnly,
<i>231</i>&nbsp;                          int checkFeasableCount,
<i>232</i>&nbsp;                          UniformRandomProvider rng,
<i>233</i>&nbsp;                          boolean generateStatistics,
<i>234</i>&nbsp;                          ConvergenceChecker&lt;PointValuePair&gt; checker) {
<b class="fc"><i>235</i>&nbsp;        super(checker);</b>
<b class="fc"><i>236</i>&nbsp;        this.maxIterations = maxIterations;</b>
<b class="fc"><i>237</i>&nbsp;        this.stopFitness = stopFitness;</b>
<b class="fc"><i>238</i>&nbsp;        this.isActiveCMA = isActiveCMA;</b>
<b class="fc"><i>239</i>&nbsp;        this.diagonalOnly = diagonalOnly;</b>
<b class="fc"><i>240</i>&nbsp;        this.checkFeasableCount = checkFeasableCount;</b>
<b class="fc"><i>241</i>&nbsp;        this.random = new NormalDistribution(0, 1).createSampler(rng);</b>
<b class="fc"><i>242</i>&nbsp;        this.generateStatistics = generateStatistics;</b>
<b class="fc"><i>243</i>&nbsp;    }</b>
<i>244</i>&nbsp;
<i>245</i>&nbsp;    /**
<i>246</i>&nbsp;     * @return History of sigma values.
<i>247</i>&nbsp;     */
<i>248</i>&nbsp;    public List&lt;Double&gt; getStatisticsSigmaHistory() {
<b class="nc"><i>249</i>&nbsp;        return statisticsSigmaHistory;</b>
<i>250</i>&nbsp;    }
<i>251</i>&nbsp;
<i>252</i>&nbsp;    /**
<i>253</i>&nbsp;     * @return History of mean matrix.
<i>254</i>&nbsp;     */
<i>255</i>&nbsp;    public List&lt;RealMatrix&gt; getStatisticsMeanHistory() {
<b class="nc"><i>256</i>&nbsp;        return statisticsMeanHistory;</b>
<i>257</i>&nbsp;    }
<i>258</i>&nbsp;
<i>259</i>&nbsp;    /**
<i>260</i>&nbsp;     * @return History of fitness values.
<i>261</i>&nbsp;     */
<i>262</i>&nbsp;    public List&lt;Double&gt; getStatisticsFitnessHistory() {
<b class="nc"><i>263</i>&nbsp;        return statisticsFitnessHistory;</b>
<i>264</i>&nbsp;    }
<i>265</i>&nbsp;
<i>266</i>&nbsp;    /**
<i>267</i>&nbsp;     * @return History of D matrix.
<i>268</i>&nbsp;     */
<i>269</i>&nbsp;    public List&lt;RealMatrix&gt; getStatisticsDHistory() {
<b class="nc"><i>270</i>&nbsp;        return statisticsDHistory;</b>
<i>271</i>&nbsp;    }
<i>272</i>&nbsp;
<i>273</i>&nbsp;    /**
<i>274</i>&nbsp;     * Input sigma values.
<i>275</i>&nbsp;     * They define the initial coordinate-wise standard deviations for
<i>276</i>&nbsp;     * sampling new search points around the initial guess.
<i>277</i>&nbsp;     * It is suggested to set them to the estimated distance from the
<i>278</i>&nbsp;     * initial to the desired optimum.
<i>279</i>&nbsp;     * Small values induce the search to be more local (and very small
<i>280</i>&nbsp;     * values are more likely to find a local optimum close to the initial
<i>281</i>&nbsp;     * guess).
<i>282</i>&nbsp;     * Too small values might however lead to early termination.
<i>283</i>&nbsp;     */
<i>284</i>&nbsp;    public static class Sigma implements OptimizationData {
<i>285</i>&nbsp;        /** Sigma values. */
<i>286</i>&nbsp;        private final double[] sigma;
<i>287</i>&nbsp;
<i>288</i>&nbsp;        /**
<i>289</i>&nbsp;         * @param s Sigma values.
<i>290</i>&nbsp;         * @throws NotPositiveException if any of the array entries is smaller
<i>291</i>&nbsp;         * than zero.
<i>292</i>&nbsp;         */
<i>293</i>&nbsp;        public Sigma(double[] s)
<b class="fc"><i>294</i>&nbsp;            throws NotPositiveException {</b>
<b class="fc"><i>295</i>&nbsp;            for (int i = 0; i &lt; s.length; i++) {</b>
<b class="fc"><i>296</i>&nbsp;                if (s[i] &lt; 0) {</b>
<b class="fc"><i>297</i>&nbsp;                    throw new NotPositiveException(s[i]);</b>
<i>298</i>&nbsp;                }
<i>299</i>&nbsp;            }
<i>300</i>&nbsp;
<b class="fc"><i>301</i>&nbsp;            sigma = s.clone();</b>
<b class="fc"><i>302</i>&nbsp;        }</b>
<i>303</i>&nbsp;
<i>304</i>&nbsp;        /**
<i>305</i>&nbsp;         * @return the sigma values.
<i>306</i>&nbsp;         */
<i>307</i>&nbsp;        public double[] getSigma() {
<b class="fc"><i>308</i>&nbsp;            return sigma.clone();</b>
<i>309</i>&nbsp;        }
<i>310</i>&nbsp;    }
<i>311</i>&nbsp;
<i>312</i>&nbsp;    /**
<i>313</i>&nbsp;     * Population size.
<i>314</i>&nbsp;     * The number of offspring is the primary strategy parameter.
<i>315</i>&nbsp;     * In the absence of better clues, a good default could be an
<i>316</i>&nbsp;     * integer close to {@code 4 + 3 ln(n)}, where {@code n} is the
<i>317</i>&nbsp;     * number of optimized parameters.
<i>318</i>&nbsp;     * Increasing the population size improves global search properties
<i>319</i>&nbsp;     * at the expense of speed (which in general decreases at most
<i>320</i>&nbsp;     * linearly with increasing population size).
<i>321</i>&nbsp;     */
<i>322</i>&nbsp;    public static class PopulationSize implements OptimizationData {
<i>323</i>&nbsp;        /** Population size. */
<i>324</i>&nbsp;        private final int lambda;
<i>325</i>&nbsp;
<i>326</i>&nbsp;        /**
<i>327</i>&nbsp;         * @param size Population size.
<i>328</i>&nbsp;         * @throws NotStrictlyPositiveException if {@code size &lt;= 0}.
<i>329</i>&nbsp;         */
<i>330</i>&nbsp;        public PopulationSize(int size)
<b class="fc"><i>331</i>&nbsp;            throws NotStrictlyPositiveException {</b>
<b class="fc"><i>332</i>&nbsp;            if (size &lt;= 0) {</b>
<b class="nc"><i>333</i>&nbsp;                throw new NotStrictlyPositiveException(size);</b>
<i>334</i>&nbsp;            }
<b class="fc"><i>335</i>&nbsp;            lambda = size;</b>
<b class="fc"><i>336</i>&nbsp;        }</b>
<i>337</i>&nbsp;
<i>338</i>&nbsp;        /**
<i>339</i>&nbsp;         * @return the population size.
<i>340</i>&nbsp;         */
<i>341</i>&nbsp;        public int getPopulationSize() {
<b class="fc"><i>342</i>&nbsp;            return lambda;</b>
<i>343</i>&nbsp;        }
<i>344</i>&nbsp;    }
<i>345</i>&nbsp;
<i>346</i>&nbsp;    /**
<i>347</i>&nbsp;     * {@inheritDoc}
<i>348</i>&nbsp;     *
<i>349</i>&nbsp;     * @param optData Optimization data. In addition to those documented in
<i>350</i>&nbsp;     * {@link MultivariateOptimizer#parseOptimizationData(OptimizationData[])
<i>351</i>&nbsp;     * MultivariateOptimizer}, this method will register the following data:
<i>352</i>&nbsp;     * &lt;ul&gt;
<i>353</i>&nbsp;     *  &lt;li&gt;{@link Sigma}&lt;/li&gt;
<i>354</i>&nbsp;     *  &lt;li&gt;{@link PopulationSize}&lt;/li&gt;
<i>355</i>&nbsp;     * &lt;/ul&gt;
<i>356</i>&nbsp;     * @return {@inheritDoc}
<i>357</i>&nbsp;     * @throws TooManyEvaluationsException if the maximal number of
<i>358</i>&nbsp;     * evaluations is exceeded.
<i>359</i>&nbsp;     * @throws DimensionMismatchException if the initial guess, target, and weight
<i>360</i>&nbsp;     * arguments have inconsistent dimensions.
<i>361</i>&nbsp;     */
<i>362</i>&nbsp;    @Override
<i>363</i>&nbsp;    public PointValuePair optimize(OptimizationData... optData)
<i>364</i>&nbsp;        throws TooManyEvaluationsException,
<i>365</i>&nbsp;               DimensionMismatchException {
<i>366</i>&nbsp;        // Set up base class and perform computation.
<b class="fc"><i>367</i>&nbsp;        return super.optimize(optData);</b>
<i>368</i>&nbsp;    }
<i>369</i>&nbsp;
<i>370</i>&nbsp;    /** {@inheritDoc} */
<i>371</i>&nbsp;    @Override
<i>372</i>&nbsp;    protected PointValuePair doOptimize() {
<i>373</i>&nbsp;         // -------------------- Initialization --------------------------------
<b class="fc"><i>374</i>&nbsp;        isMinimize = getGoalType().equals(GoalType.MINIMIZE);</b>
<b class="fc"><i>375</i>&nbsp;        final FitnessFunction fitfun = new FitnessFunction();</b>
<b class="fc"><i>376</i>&nbsp;        final double[] guess = getStartPoint();</b>
<i>377</i>&nbsp;        // number of objective variables/problem dimension
<b class="fc"><i>378</i>&nbsp;        dimension = guess.length;</b>
<b class="fc"><i>379</i>&nbsp;        initializeCMA(guess);</b>
<b class="fc"><i>380</i>&nbsp;        iterations = 0;</b>
<b class="fc"><i>381</i>&nbsp;        ValuePenaltyPair valuePenalty = fitfun.value(guess);</b>
<b class="fc"><i>382</i>&nbsp;        double bestValue = valuePenalty.value+valuePenalty.penalty;</b>
<b class="fc"><i>383</i>&nbsp;        push(fitnessHistory, bestValue);</b>
<b class="fc"><i>384</i>&nbsp;        PointValuePair optimum</b>
<b class="fc"><i>385</i>&nbsp;            = new PointValuePair(getStartPoint(),</b>
<i>386</i>&nbsp;                                 isMinimize ? bestValue : -bestValue);
<b class="fc"><i>387</i>&nbsp;        PointValuePair lastResult = null;</b>
<i>388</i>&nbsp;
<i>389</i>&nbsp;        // -------------------- Generation Loop --------------------------------
<i>390</i>&nbsp;
<i>391</i>&nbsp;        generationLoop:
<b class="fc"><i>392</i>&nbsp;        for (iterations = 1; iterations &lt;= maxIterations; iterations++) {</b>
<b class="fc"><i>393</i>&nbsp;            incrementIterationCount();</b>
<i>394</i>&nbsp;
<i>395</i>&nbsp;            // Generate and evaluate lambda offspring
<b class="fc"><i>396</i>&nbsp;            final RealMatrix arz = randn1(dimension, lambda);</b>
<b class="fc"><i>397</i>&nbsp;            final RealMatrix arx = zeros(dimension, lambda);</b>
<b class="fc"><i>398</i>&nbsp;            final double[] fitness = new double[lambda];</b>
<b class="fc"><i>399</i>&nbsp;            final ValuePenaltyPair[] valuePenaltyPairs = new ValuePenaltyPair[lambda];</b>
<i>400</i>&nbsp;            // generate random offspring
<b class="fc"><i>401</i>&nbsp;            for (int k = 0; k &lt; lambda; k++) {</b>
<b class="fc"><i>402</i>&nbsp;                RealMatrix arxk = null;</b>
<b class="fc"><i>403</i>&nbsp;                for (int i = 0; i &lt; checkFeasableCount + 1; i++) {</b>
<b class="fc"><i>404</i>&nbsp;                    if (diagonalOnly &lt;= 0) {</b>
<b class="fc"><i>405</i>&nbsp;                        arxk = xmean.add(BD.multiply(arz.getColumnMatrix(k))</b>
<b class="fc"><i>406</i>&nbsp;                                         .scalarMultiply(sigma)); // m + sig * Normal(0,C)</b>
<i>407</i>&nbsp;                    } else {
<b class="fc"><i>408</i>&nbsp;                        arxk = xmean.add(times(diagD,arz.getColumnMatrix(k))</b>
<b class="fc"><i>409</i>&nbsp;                                         .scalarMultiply(sigma));</b>
<i>410</i>&nbsp;                    }
<b class="fc"><i>411</i>&nbsp;                    if (i &gt;= checkFeasableCount ||</b>
<b class="nc"><i>412</i>&nbsp;                        fitfun.isFeasible(arxk.getColumn(0))) {</b>
<b class="nc"><i>413</i>&nbsp;                        break;</b>
<i>414</i>&nbsp;                    }
<i>415</i>&nbsp;                    // regenerate random arguments for row
<b class="nc"><i>416</i>&nbsp;                    arz.setColumn(k, randn(dimension));</b>
<i>417</i>&nbsp;                }
<b class="fc"><i>418</i>&nbsp;                copyColumn(arxk, 0, arx, k);</b>
<i>419</i>&nbsp;                try {
<b class="fc"><i>420</i>&nbsp;                    valuePenaltyPairs[k] = fitfun.value(arx.getColumn(k)); // compute fitness</b>
<b class="nc"><i>421</i>&nbsp;                } catch (TooManyEvaluationsException e) {</b>
<b class="nc"><i>422</i>&nbsp;                    break generationLoop;</b>
<b class="fc"><i>423</i>&nbsp;                }</b>
<i>424</i>&nbsp;            }
<i>425</i>&nbsp;
<i>426</i>&nbsp;            // Compute fitnesses by adding value and penalty after scaling by value range.
<b class="fc"><i>427</i>&nbsp;            double valueRange = valueRange(valuePenaltyPairs);</b>
<b class="fc"><i>428</i>&nbsp;            for (int iValue=0;iValue&lt;valuePenaltyPairs.length;iValue++) {</b>
<b class="fc"><i>429</i>&nbsp;                 fitness[iValue] = valuePenaltyPairs[iValue].value + valuePenaltyPairs[iValue].penalty*valueRange;</b>
<i>430</i>&nbsp;            }
<i>431</i>&nbsp;
<i>432</i>&nbsp;            // Sort by fitness and compute weighted mean into xmean
<b class="fc"><i>433</i>&nbsp;            final int[] arindex = sortedIndices(fitness);</b>
<i>434</i>&nbsp;            // Calculate new xmean, this is selection and recombination
<b class="fc"><i>435</i>&nbsp;            final RealMatrix xold = xmean; // for speed up of Eq. (2) and (3)</b>
<b class="fc"><i>436</i>&nbsp;            final RealMatrix bestArx = selectColumns(arx, MathArrays.copyOf(arindex, mu));</b>
<b class="fc"><i>437</i>&nbsp;            xmean = bestArx.multiply(weights);</b>
<b class="fc"><i>438</i>&nbsp;            final RealMatrix bestArz = selectColumns(arz, MathArrays.copyOf(arindex, mu));</b>
<b class="fc"><i>439</i>&nbsp;            final RealMatrix zmean = bestArz.multiply(weights);</b>
<b class="fc"><i>440</i>&nbsp;            final boolean hsig = updateEvolutionPaths(zmean, xold);</b>
<b class="fc"><i>441</i>&nbsp;            if (diagonalOnly &lt;= 0) {</b>
<b class="fc"><i>442</i>&nbsp;                updateCovariance(hsig, bestArx, arz, arindex, xold);</b>
<i>443</i>&nbsp;            } else {
<b class="fc"><i>444</i>&nbsp;                updateCovarianceDiagonalOnly(hsig, bestArz);</b>
<i>445</i>&nbsp;            }
<i>446</i>&nbsp;            // Adapt step size sigma - Eq. (5)
<b class="fc"><i>447</i>&nbsp;            sigma *= FastMath.exp(FastMath.min(1, (normps/chiN - 1) * cs / damps));</b>
<b class="fc"><i>448</i>&nbsp;            final double bestFitness = fitness[arindex[0]];</b>
<b class="fc"><i>449</i>&nbsp;            final double worstFitness = fitness[arindex[arindex.length - 1]];</b>
<b class="fc"><i>450</i>&nbsp;            if (bestValue &gt; bestFitness) {</b>
<b class="fc"><i>451</i>&nbsp;                bestValue = bestFitness;</b>
<b class="fc"><i>452</i>&nbsp;                lastResult = optimum;</b>
<b class="fc"><i>453</i>&nbsp;                optimum = new PointValuePair(fitfun.repair(bestArx.getColumn(0)),</b>
<i>454</i>&nbsp;                                             isMinimize ? bestFitness : -bestFitness);
<b class="fc"><i>455</i>&nbsp;                if (getConvergenceChecker() != null &amp;&amp; lastResult != null &amp;&amp;</b>
<b class="nc"><i>456</i>&nbsp;                    getConvergenceChecker().converged(iterations, optimum, lastResult)) {</b>
<b class="nc"><i>457</i>&nbsp;                    break generationLoop;</b>
<i>458</i>&nbsp;                }
<i>459</i>&nbsp;            }
<i>460</i>&nbsp;            // handle termination criteria
<i>461</i>&nbsp;            // Break, if fitness is good enough
<b class="fc"><i>462</i>&nbsp;            if (stopFitness != 0 &amp;&amp; bestFitness &lt; (isMinimize ? stopFitness : -stopFitness)) {</b>
<b class="fc"><i>463</i>&nbsp;                break generationLoop;</b>
<i>464</i>&nbsp;            }
<b class="fc"><i>465</i>&nbsp;            final double[] sqrtDiagC = sqrt(diagC).getColumn(0);</b>
<b class="fc"><i>466</i>&nbsp;            final double[] pcCol = pc.getColumn(0);</b>
<b class="fc"><i>467</i>&nbsp;            for (int i = 0; i &lt; dimension; i++) {</b>
<b class="fc"><i>468</i>&nbsp;                if (sigma * FastMath.max(FastMath.abs(pcCol[i]), sqrtDiagC[i]) &gt; stopTolX) {</b>
<b class="fc"><i>469</i>&nbsp;                    break;</b>
<i>470</i>&nbsp;                }
<b class="fc"><i>471</i>&nbsp;                if (i &gt;= dimension - 1) {</b>
<b class="fc"><i>472</i>&nbsp;                    break generationLoop;</b>
<i>473</i>&nbsp;                }
<i>474</i>&nbsp;            }
<b class="fc"><i>475</i>&nbsp;            for (int i = 0; i &lt; dimension; i++) {</b>
<b class="fc"><i>476</i>&nbsp;                if (sigma * sqrtDiagC[i] &gt; stopTolUpX) {</b>
<b class="nc"><i>477</i>&nbsp;                    break generationLoop;</b>
<i>478</i>&nbsp;                }
<i>479</i>&nbsp;            }
<b class="fc"><i>480</i>&nbsp;            final double historyBest = min(fitnessHistory);</b>
<b class="fc"><i>481</i>&nbsp;            final double historyWorst = max(fitnessHistory);</b>
<b class="fc"><i>482</i>&nbsp;            if (iterations &gt; 2 &amp;&amp;</b>
<b class="fc"><i>483</i>&nbsp;                FastMath.max(historyWorst, worstFitness) -</b>
<b class="fc"><i>484</i>&nbsp;                FastMath.min(historyBest, bestFitness) &lt; stopTolFun) {</b>
<b class="fc"><i>485</i>&nbsp;                break generationLoop;</b>
<i>486</i>&nbsp;            }
<b class="fc"><i>487</i>&nbsp;            if (iterations &gt; fitnessHistory.length &amp;&amp;</b>
<i>488</i>&nbsp;                historyWorst - historyBest &lt; stopTolHistFun) {
<b class="nc"><i>489</i>&nbsp;                break generationLoop;</b>
<i>490</i>&nbsp;            }
<i>491</i>&nbsp;            // condition number of the covariance matrix exceeds 1e14
<b class="fc"><i>492</i>&nbsp;            if (max(diagD) / min(diagD) &gt; 1e7) {</b>
<b class="fc"><i>493</i>&nbsp;                break generationLoop;</b>
<i>494</i>&nbsp;            }
<i>495</i>&nbsp;            // user defined termination
<b class="fc"><i>496</i>&nbsp;            if (getConvergenceChecker() != null) {</b>
<b class="nc"><i>497</i>&nbsp;                final PointValuePair current</b>
<b class="nc"><i>498</i>&nbsp;                    = new PointValuePair(bestArx.getColumn(0),</b>
<i>499</i>&nbsp;                                         isMinimize ? bestFitness : -bestFitness);
<b class="nc"><i>500</i>&nbsp;                if (lastResult != null &amp;&amp;</b>
<b class="nc"><i>501</i>&nbsp;                    getConvergenceChecker().converged(iterations, current, lastResult)) {</b>
<b class="nc"><i>502</i>&nbsp;                    break generationLoop;</b>
<i>503</i>&nbsp;                    }
<b class="nc"><i>504</i>&nbsp;                lastResult = current;</b>
<i>505</i>&nbsp;            }
<i>506</i>&nbsp;            // Adjust step size in case of equal function values (flat fitness)
<b class="fc"><i>507</i>&nbsp;            if (bestValue == fitness[arindex[(int)(0.1+lambda/4.)]]) {</b>
<b class="fc"><i>508</i>&nbsp;                sigma *= FastMath.exp(0.2 + cs / damps);</b>
<i>509</i>&nbsp;            }
<b class="fc"><i>510</i>&nbsp;            if (iterations &gt; 2 &amp;&amp; FastMath.max(historyWorst, bestFitness) -</b>
<b class="fc"><i>511</i>&nbsp;                FastMath.min(historyBest, bestFitness) == 0) {</b>
<b class="nc"><i>512</i>&nbsp;                sigma *= FastMath.exp(0.2 + cs / damps);</b>
<i>513</i>&nbsp;            }
<i>514</i>&nbsp;            // store best in history
<b class="fc"><i>515</i>&nbsp;            push(fitnessHistory,bestFitness);</b>
<b class="fc"><i>516</i>&nbsp;            if (generateStatistics) {</b>
<b class="nc"><i>517</i>&nbsp;                statisticsSigmaHistory.add(sigma);</b>
<b class="nc"><i>518</i>&nbsp;                statisticsFitnessHistory.add(bestFitness);</b>
<b class="nc"><i>519</i>&nbsp;                statisticsMeanHistory.add(xmean.transpose());</b>
<b class="nc"><i>520</i>&nbsp;                statisticsDHistory.add(diagD.transpose().scalarMultiply(1E5));</b>
<i>521</i>&nbsp;            }
<i>522</i>&nbsp;        }
<b class="fc"><i>523</i>&nbsp;        return optimum;</b>
<i>524</i>&nbsp;    }
<i>525</i>&nbsp;
<i>526</i>&nbsp;    /**
<i>527</i>&nbsp;     * Scans the list of (required and optional) optimization data that
<i>528</i>&nbsp;     * characterize the problem.
<i>529</i>&nbsp;     *
<i>530</i>&nbsp;     * @param optData Optimization data. The following data will be looked for:
<i>531</i>&nbsp;     * &lt;ul&gt;
<i>532</i>&nbsp;     *  &lt;li&gt;{@link Sigma}&lt;/li&gt;
<i>533</i>&nbsp;     *  &lt;li&gt;{@link PopulationSize}&lt;/li&gt;
<i>534</i>&nbsp;     * &lt;/ul&gt;
<i>535</i>&nbsp;     */
<i>536</i>&nbsp;    @Override
<i>537</i>&nbsp;    protected void parseOptimizationData(OptimizationData... optData) {
<i>538</i>&nbsp;        // Allow base class to register its own data.
<b class="fc"><i>539</i>&nbsp;        super.parseOptimizationData(optData);</b>
<i>540</i>&nbsp;
<i>541</i>&nbsp;        // The existing values (as set by the previous call) are reused if
<i>542</i>&nbsp;        // not provided in the argument list.
<b class="fc"><i>543</i>&nbsp;        for (OptimizationData data : optData) {</b>
<b class="fc"><i>544</i>&nbsp;            if (data instanceof Sigma) {</b>
<b class="fc"><i>545</i>&nbsp;                inputSigma = ((Sigma) data).getSigma();</b>
<b class="fc"><i>546</i>&nbsp;                continue;</b>
<i>547</i>&nbsp;            }
<b class="fc"><i>548</i>&nbsp;            if (data instanceof PopulationSize) {</b>
<b class="fc"><i>549</i>&nbsp;                lambda = ((PopulationSize) data).getPopulationSize();</b>
<b class="fc"><i>550</i>&nbsp;                continue;</b>
<i>551</i>&nbsp;            }
<i>552</i>&nbsp;        }
<i>553</i>&nbsp;
<b class="fc"><i>554</i>&nbsp;        checkParameters();</b>
<b class="fc"><i>555</i>&nbsp;    }</b>
<i>556</i>&nbsp;
<i>557</i>&nbsp;    /**
<i>558</i>&nbsp;     * Checks dimensions and values of boundaries and inputSigma if defined.
<i>559</i>&nbsp;     */
<i>560</i>&nbsp;    private void checkParameters() {
<b class="fc"><i>561</i>&nbsp;        if (inputSigma != null) {</b>
<b class="fc"><i>562</i>&nbsp;            final double[] init = getStartPoint();</b>
<i>563</i>&nbsp;
<b class="fc"><i>564</i>&nbsp;            if (inputSigma.length != init.length) {</b>
<b class="fc"><i>565</i>&nbsp;                throw new DimensionMismatchException(inputSigma.length, init.length);</b>
<i>566</i>&nbsp;            }
<i>567</i>&nbsp;
<b class="fc"><i>568</i>&nbsp;            final double[] lB = getLowerBound();</b>
<b class="fc"><i>569</i>&nbsp;            final double[] uB = getUpperBound();</b>
<i>570</i>&nbsp;
<b class="fc"><i>571</i>&nbsp;            for (int i = 0; i &lt; init.length; i++) {</b>
<b class="fc"><i>572</i>&nbsp;                if (inputSigma[i] &gt; uB[i] - lB[i]) {</b>
<b class="fc"><i>573</i>&nbsp;                    throw new OutOfRangeException(inputSigma[i], 0, uB[i] - lB[i]);</b>
<i>574</i>&nbsp;                }
<i>575</i>&nbsp;            }
<i>576</i>&nbsp;        }
<b class="fc"><i>577</i>&nbsp;    }</b>
<i>578</i>&nbsp;
<i>579</i>&nbsp;    /**
<i>580</i>&nbsp;     * Initialization of the dynamic search parameters
<i>581</i>&nbsp;     *
<i>582</i>&nbsp;     * @param guess Initial guess for the arguments of the fitness function.
<i>583</i>&nbsp;     */
<i>584</i>&nbsp;    private void initializeCMA(double[] guess) {
<b class="fc"><i>585</i>&nbsp;        if (lambda &lt;= 0) {</b>
<b class="nc"><i>586</i>&nbsp;            throw new NotStrictlyPositiveException(lambda);</b>
<i>587</i>&nbsp;        }
<i>588</i>&nbsp;        // initialize sigma
<b class="fc"><i>589</i>&nbsp;        final double[][] sigmaArray = new double[guess.length][1];</b>
<b class="fc"><i>590</i>&nbsp;        for (int i = 0; i &lt; guess.length; i++) {</b>
<b class="fc"><i>591</i>&nbsp;            sigmaArray[i][0] = inputSigma[i];</b>
<i>592</i>&nbsp;        }
<b class="fc"><i>593</i>&nbsp;        final RealMatrix insigma = new Array2DRowRealMatrix(sigmaArray, false);</b>
<b class="fc"><i>594</i>&nbsp;        sigma = max(insigma); // overall standard deviation</b>
<i>595</i>&nbsp;
<i>596</i>&nbsp;        // initialize termination criteria
<b class="fc"><i>597</i>&nbsp;        stopTolUpX = 1e3 * max(insigma);</b>
<b class="fc"><i>598</i>&nbsp;        stopTolX = 1e-11 * max(insigma);</b>
<b class="fc"><i>599</i>&nbsp;        stopTolFun = 1e-12;</b>
<b class="fc"><i>600</i>&nbsp;        stopTolHistFun = 1e-13;</b>
<i>601</i>&nbsp;
<i>602</i>&nbsp;        // initialize selection strategy parameters
<b class="fc"><i>603</i>&nbsp;        mu = lambda / 2; // number of parents/points for recombination</b>
<b class="fc"><i>604</i>&nbsp;        logMu2 = FastMath.log(mu + 0.5);</b>
<b class="fc"><i>605</i>&nbsp;        weights = log(sequence(1, mu, 1)).scalarMultiply(-1).scalarAdd(logMu2);</b>
<b class="fc"><i>606</i>&nbsp;        double sumw = 0;</b>
<b class="fc"><i>607</i>&nbsp;        double sumwq = 0;</b>
<b class="fc"><i>608</i>&nbsp;        for (int i = 0; i &lt; mu; i++) {</b>
<b class="fc"><i>609</i>&nbsp;            double w = weights.getEntry(i, 0);</b>
<b class="fc"><i>610</i>&nbsp;            sumw += w;</b>
<b class="fc"><i>611</i>&nbsp;            sumwq += w * w;</b>
<i>612</i>&nbsp;        }
<b class="fc"><i>613</i>&nbsp;        weights = weights.scalarMultiply(1 / sumw);</b>
<b class="fc"><i>614</i>&nbsp;        mueff = sumw * sumw / sumwq; // variance-effectiveness of sum w_i x_i</b>
<i>615</i>&nbsp;
<i>616</i>&nbsp;        // initialize dynamic strategy parameters and constants
<b class="fc"><i>617</i>&nbsp;        cc = (4 + mueff / dimension) /</b>
<i>618</i>&nbsp;                (dimension + 4 + 2 * mueff / dimension);
<b class="fc"><i>619</i>&nbsp;        cs = (mueff + 2) / (dimension + mueff + 3.);</b>
<b class="fc"><i>620</i>&nbsp;        damps = (1 + 2 * FastMath.max(0, FastMath.sqrt((mueff - 1) /</b>
<i>621</i>&nbsp;                                                       (dimension + 1)) - 1)) *
<b class="fc"><i>622</i>&nbsp;            FastMath.max(0.3,</b>
<i>623</i>&nbsp;                         1 - dimension / (1e-6 + maxIterations)) + cs; // minor increment
<b class="fc"><i>624</i>&nbsp;        ccov1 = 2 / ((dimension + 1.3) * (dimension + 1.3) + mueff);</b>
<b class="fc"><i>625</i>&nbsp;        ccovmu = FastMath.min(1 - ccov1, 2 * (mueff - 2 + 1 / mueff) /</b>
<i>626</i>&nbsp;                              ((dimension + 2) * (dimension + 2) + mueff));
<b class="fc"><i>627</i>&nbsp;        ccov1Sep = FastMath.min(1, ccov1 * (dimension + 1.5) / 3);</b>
<b class="fc"><i>628</i>&nbsp;        ccovmuSep = FastMath.min(1 - ccov1, ccovmu * (dimension + 1.5) / 3);</b>
<b class="fc"><i>629</i>&nbsp;        chiN = FastMath.sqrt(dimension) *</b>
<i>630</i>&nbsp;                (1 - 1 / ((double) 4 * dimension) + 1 / ((double) 21 * dimension * dimension));
<i>631</i>&nbsp;        // intialize CMA internal values - updated each generation
<b class="fc"><i>632</i>&nbsp;        xmean = MatrixUtils.createColumnRealMatrix(guess); // objective variables</b>
<b class="fc"><i>633</i>&nbsp;        diagD = insigma.scalarMultiply(1 / sigma);</b>
<b class="fc"><i>634</i>&nbsp;        diagC = square(diagD);</b>
<b class="fc"><i>635</i>&nbsp;        pc = zeros(dimension, 1); // evolution paths for C and sigma</b>
<b class="fc"><i>636</i>&nbsp;        ps = zeros(dimension, 1); // B defines the coordinate system</b>
<b class="fc"><i>637</i>&nbsp;        normps = ps.getFrobeniusNorm();</b>
<i>638</i>&nbsp;
<b class="fc"><i>639</i>&nbsp;        B = eye(dimension, dimension);</b>
<b class="fc"><i>640</i>&nbsp;        D = ones(dimension, 1); // diagonal D defines the scaling</b>
<b class="fc"><i>641</i>&nbsp;        BD = times(B, repmat(diagD.transpose(), dimension, 1));</b>
<b class="fc"><i>642</i>&nbsp;        C = B.multiply(diag(square(D)).multiply(B.transpose())); // covariance</b>
<b class="fc"><i>643</i>&nbsp;        historySize = 10 + (int) (3 * 10 * dimension / (double) lambda);</b>
<b class="fc"><i>644</i>&nbsp;        fitnessHistory = new double[historySize]; // history of fitness values</b>
<b class="fc"><i>645</i>&nbsp;        for (int i = 0; i &lt; historySize; i++) {</b>
<b class="fc"><i>646</i>&nbsp;            fitnessHistory[i] = Double.MAX_VALUE;</b>
<i>647</i>&nbsp;        }
<b class="fc"><i>648</i>&nbsp;    }</b>
<i>649</i>&nbsp;
<i>650</i>&nbsp;    /**
<i>651</i>&nbsp;     * Update of the evolution paths ps and pc.
<i>652</i>&nbsp;     *
<i>653</i>&nbsp;     * @param zmean Weighted row matrix of the gaussian random numbers generating
<i>654</i>&nbsp;     * the current offspring.
<i>655</i>&nbsp;     * @param xold xmean matrix of the previous generation.
<i>656</i>&nbsp;     * @return hsig flag indicating a small correction.
<i>657</i>&nbsp;     */
<i>658</i>&nbsp;    private boolean updateEvolutionPaths(RealMatrix zmean, RealMatrix xold) {
<b class="fc"><i>659</i>&nbsp;        ps = ps.scalarMultiply(1 - cs).add(</b>
<b class="fc"><i>660</i>&nbsp;                B.multiply(zmean).scalarMultiply(</b>
<b class="fc"><i>661</i>&nbsp;                        FastMath.sqrt(cs * (2 - cs) * mueff)));</b>
<b class="fc"><i>662</i>&nbsp;        normps = ps.getFrobeniusNorm();</b>
<b class="fc"><i>663</i>&nbsp;        final boolean hsig = normps /</b>
<b class="fc"><i>664</i>&nbsp;            FastMath.sqrt(1 - FastMath.pow(1 - cs, 2 * iterations)) /</b>
<i>665</i>&nbsp;            chiN &lt; 1.4 + 2 / ((double) dimension + 1);
<b class="fc"><i>666</i>&nbsp;        pc = pc.scalarMultiply(1 - cc);</b>
<b class="fc"><i>667</i>&nbsp;        if (hsig) {</b>
<b class="fc"><i>668</i>&nbsp;            pc = pc.add(xmean.subtract(xold).scalarMultiply(FastMath.sqrt(cc * (2 - cc) * mueff) / sigma));</b>
<i>669</i>&nbsp;        }
<b class="fc"><i>670</i>&nbsp;        return hsig;</b>
<i>671</i>&nbsp;    }
<i>672</i>&nbsp;
<i>673</i>&nbsp;    /**
<i>674</i>&nbsp;     * Update of the covariance matrix C for diagonalOnly &gt; 0
<i>675</i>&nbsp;     *
<i>676</i>&nbsp;     * @param hsig Flag indicating a small correction.
<i>677</i>&nbsp;     * @param bestArz Fitness-sorted matrix of the gaussian random values of the
<i>678</i>&nbsp;     * current offspring.
<i>679</i>&nbsp;     */
<i>680</i>&nbsp;    private void updateCovarianceDiagonalOnly(boolean hsig,
<i>681</i>&nbsp;                                              final RealMatrix bestArz) {
<i>682</i>&nbsp;        // minor correction if hsig==false
<b class="fc"><i>683</i>&nbsp;        double oldFac = hsig ? 0 : ccov1Sep * cc * (2 - cc);</b>
<b class="fc"><i>684</i>&nbsp;        oldFac += 1 - ccov1Sep - ccovmuSep;</b>
<b class="fc"><i>685</i>&nbsp;        diagC = diagC.scalarMultiply(oldFac) // regard old matrix</b>
<b class="fc"><i>686</i>&nbsp;            .add(square(pc).scalarMultiply(ccov1Sep)) // plus rank one update</b>
<b class="fc"><i>687</i>&nbsp;            .add((times(diagC, square(bestArz).multiply(weights))) // plus rank mu update</b>
<b class="fc"><i>688</i>&nbsp;                 .scalarMultiply(ccovmuSep));</b>
<b class="fc"><i>689</i>&nbsp;        diagD = sqrt(diagC); // replaces eig(C)</b>
<b class="fc"><i>690</i>&nbsp;        if (diagonalOnly &gt; 1 &amp;&amp;</b>
<i>691</i>&nbsp;            iterations &gt; diagonalOnly) {
<i>692</i>&nbsp;            // full covariance matrix from now on
<b class="fc"><i>693</i>&nbsp;            diagonalOnly = 0;</b>
<b class="fc"><i>694</i>&nbsp;            B = eye(dimension, dimension);</b>
<b class="fc"><i>695</i>&nbsp;            BD = diag(diagD);</b>
<b class="fc"><i>696</i>&nbsp;            C = diag(diagC);</b>
<i>697</i>&nbsp;        }
<b class="fc"><i>698</i>&nbsp;    }</b>
<i>699</i>&nbsp;
<i>700</i>&nbsp;    /**
<i>701</i>&nbsp;     * Update of the covariance matrix C.
<i>702</i>&nbsp;     *
<i>703</i>&nbsp;     * @param hsig Flag indicating a small correction.
<i>704</i>&nbsp;     * @param bestArx Fitness-sorted matrix of the argument vectors producing the
<i>705</i>&nbsp;     * current offspring.
<i>706</i>&nbsp;     * @param arz Unsorted matrix containing the gaussian random values of the
<i>707</i>&nbsp;     * current offspring.
<i>708</i>&nbsp;     * @param arindex Indices indicating the fitness-order of the current offspring.
<i>709</i>&nbsp;     * @param xold xmean matrix of the previous generation.
<i>710</i>&nbsp;     */
<i>711</i>&nbsp;    private void updateCovariance(boolean hsig, final RealMatrix bestArx,
<i>712</i>&nbsp;                                  final RealMatrix arz, final int[] arindex,
<i>713</i>&nbsp;                                  final RealMatrix xold) {
<b class="fc"><i>714</i>&nbsp;        double negccov = 0;</b>
<b class="fc"><i>715</i>&nbsp;        if (ccov1 + ccovmu &gt; 0) {</b>
<b class="fc"><i>716</i>&nbsp;            final RealMatrix arpos = bestArx.subtract(repmat(xold, 1, mu))</b>
<b class="fc"><i>717</i>&nbsp;                .scalarMultiply(1 / sigma); // mu difference vectors</b>
<b class="fc"><i>718</i>&nbsp;            final RealMatrix roneu = pc.multiply(pc.transpose())</b>
<b class="fc"><i>719</i>&nbsp;                .scalarMultiply(ccov1); // rank one update</b>
<i>720</i>&nbsp;            // minor correction if hsig==false
<b class="fc"><i>721</i>&nbsp;            double oldFac = hsig ? 0 : ccov1 * cc * (2 - cc);</b>
<b class="fc"><i>722</i>&nbsp;            oldFac += 1 - ccov1 - ccovmu;</b>
<b class="fc"><i>723</i>&nbsp;            if (isActiveCMA) {</b>
<i>724</i>&nbsp;                // Adapt covariance matrix C active CMA
<b class="fc"><i>725</i>&nbsp;                negccov = (1 - ccovmu) * 0.25 * mueff /</b>
<b class="fc"><i>726</i>&nbsp;                    (FastMath.pow(dimension + 2, 1.5) + 2 * mueff);</b>
<i>727</i>&nbsp;                // keep at least 0.66 in all directions, small popsize are most
<i>728</i>&nbsp;                // critical
<b class="fc"><i>729</i>&nbsp;                final double negminresidualvariance = 0.66;</b>
<i>730</i>&nbsp;                // where to make up for the variance loss
<b class="fc"><i>731</i>&nbsp;                final double negalphaold = 0.5;</b>
<i>732</i>&nbsp;                // prepare vectors, compute negative updating matrix Cneg
<b class="fc"><i>733</i>&nbsp;                final int[] arReverseIndex = reverse(arindex);</b>
<b class="fc"><i>734</i>&nbsp;                RealMatrix arzneg = selectColumns(arz, MathArrays.copyOf(arReverseIndex, mu));</b>
<b class="fc"><i>735</i>&nbsp;                RealMatrix arnorms = sqrt(sumRows(square(arzneg)));</b>
<b class="fc"><i>736</i>&nbsp;                final int[] idxnorms = sortedIndices(arnorms.getRow(0));</b>
<b class="fc"><i>737</i>&nbsp;                final RealMatrix arnormsSorted = selectColumns(arnorms, idxnorms);</b>
<b class="fc"><i>738</i>&nbsp;                final int[] idxReverse = reverse(idxnorms);</b>
<b class="fc"><i>739</i>&nbsp;                final RealMatrix arnormsReverse = selectColumns(arnorms, idxReverse);</b>
<b class="fc"><i>740</i>&nbsp;                arnorms = divide(arnormsReverse, arnormsSorted);</b>
<b class="fc"><i>741</i>&nbsp;                final int[] idxInv = inverse(idxnorms);</b>
<b class="fc"><i>742</i>&nbsp;                final RealMatrix arnormsInv = selectColumns(arnorms, idxInv);</b>
<i>743</i>&nbsp;                // check and set learning rate negccov
<b class="fc"><i>744</i>&nbsp;                final double negcovMax = (1 - negminresidualvariance) /</b>
<b class="fc"><i>745</i>&nbsp;                    square(arnormsInv).multiply(weights).getEntry(0, 0);</b>
<b class="fc"><i>746</i>&nbsp;                if (negccov &gt; negcovMax) {</b>
<b class="fc"><i>747</i>&nbsp;                    negccov = negcovMax;</b>
<i>748</i>&nbsp;                }
<b class="fc"><i>749</i>&nbsp;                arzneg = times(arzneg, repmat(arnormsInv, dimension, 1));</b>
<b class="fc"><i>750</i>&nbsp;                final RealMatrix artmp = BD.multiply(arzneg);</b>
<b class="fc"><i>751</i>&nbsp;                final RealMatrix Cneg = artmp.multiply(diag(weights)).multiply(artmp.transpose());</b>
<b class="fc"><i>752</i>&nbsp;                oldFac += negalphaold * negccov;</b>
<b class="fc"><i>753</i>&nbsp;                C = C.scalarMultiply(oldFac)</b>
<b class="fc"><i>754</i>&nbsp;                    .add(roneu) // regard old matrix</b>
<b class="fc"><i>755</i>&nbsp;                    .add(arpos.scalarMultiply( // plus rank one update</b>
<i>756</i>&nbsp;                                              ccovmu + (1 - negalphaold) * negccov) // plus rank mu update
<b class="fc"><i>757</i>&nbsp;                         .multiply(times(repmat(weights, 1, dimension),</b>
<b class="fc"><i>758</i>&nbsp;                                         arpos.transpose())))</b>
<b class="fc"><i>759</i>&nbsp;                    .subtract(Cneg.scalarMultiply(negccov));</b>
<b class="fc"><i>760</i>&nbsp;            } else {</b>
<i>761</i>&nbsp;                // Adapt covariance matrix C - nonactive
<b class="fc"><i>762</i>&nbsp;                C = C.scalarMultiply(oldFac) // regard old matrix</b>
<b class="fc"><i>763</i>&nbsp;                    .add(roneu) // plus rank one update</b>
<b class="fc"><i>764</i>&nbsp;                    .add(arpos.scalarMultiply(ccovmu) // plus rank mu update</b>
<b class="fc"><i>765</i>&nbsp;                         .multiply(times(repmat(weights, 1, dimension),</b>
<b class="fc"><i>766</i>&nbsp;                                         arpos.transpose())));</b>
<i>767</i>&nbsp;            }
<i>768</i>&nbsp;        }
<b class="fc"><i>769</i>&nbsp;        updateBD(negccov);</b>
<b class="fc"><i>770</i>&nbsp;    }</b>
<i>771</i>&nbsp;
<i>772</i>&nbsp;    /**
<i>773</i>&nbsp;     * Update B and D from C.
<i>774</i>&nbsp;     *
<i>775</i>&nbsp;     * @param negccov Negative covariance factor.
<i>776</i>&nbsp;     */
<i>777</i>&nbsp;    private void updateBD(double negccov) {
<b class="fc"><i>778</i>&nbsp;        if (ccov1 + ccovmu + negccov &gt; 0 &amp;&amp;</b>
<i>779</i>&nbsp;            (iterations % 1. / (ccov1 + ccovmu + negccov) / dimension / 10.) &lt; 1) {
<i>780</i>&nbsp;            // to achieve O(N^2)
<b class="fc"><i>781</i>&nbsp;            C = triu(C, 0).add(triu(C, 1).transpose());</b>
<i>782</i>&nbsp;            // enforce symmetry to prevent complex numbers
<b class="fc"><i>783</i>&nbsp;            final EigenDecomposition eig = new EigenDecomposition(C);</b>
<b class="fc"><i>784</i>&nbsp;            B = eig.getV(); // eigen decomposition, B==normalized eigenvectors</b>
<b class="fc"><i>785</i>&nbsp;            D = eig.getD();</b>
<b class="fc"><i>786</i>&nbsp;            diagD = diag(D);</b>
<b class="fc"><i>787</i>&nbsp;            if (min(diagD) &lt;= 0) {</b>
<b class="nc"><i>788</i>&nbsp;                for (int i = 0; i &lt; dimension; i++) {</b>
<b class="nc"><i>789</i>&nbsp;                    if (diagD.getEntry(i, 0) &lt; 0) {</b>
<b class="nc"><i>790</i>&nbsp;                        diagD.setEntry(i, 0, 0);</b>
<i>791</i>&nbsp;                    }
<i>792</i>&nbsp;                }
<b class="nc"><i>793</i>&nbsp;                final double tfac = max(diagD) / 1e14;</b>
<b class="nc"><i>794</i>&nbsp;                C = C.add(eye(dimension, dimension).scalarMultiply(tfac));</b>
<b class="nc"><i>795</i>&nbsp;                diagD = diagD.add(ones(dimension, 1).scalarMultiply(tfac));</b>
<i>796</i>&nbsp;            }
<b class="fc"><i>797</i>&nbsp;            if (max(diagD) &gt; 1e14 * min(diagD)) {</b>
<b class="fc"><i>798</i>&nbsp;                final double tfac = max(diagD) / 1e14 - min(diagD);</b>
<b class="fc"><i>799</i>&nbsp;                C = C.add(eye(dimension, dimension).scalarMultiply(tfac));</b>
<b class="fc"><i>800</i>&nbsp;                diagD = diagD.add(ones(dimension, 1).scalarMultiply(tfac));</b>
<i>801</i>&nbsp;            }
<b class="fc"><i>802</i>&nbsp;            diagC = diag(C);</b>
<b class="fc"><i>803</i>&nbsp;            diagD = sqrt(diagD); // D contains standard deviations now</b>
<b class="fc"><i>804</i>&nbsp;            BD = times(B, repmat(diagD.transpose(), dimension, 1)); // O(n^2)</b>
<i>805</i>&nbsp;        }
<b class="fc"><i>806</i>&nbsp;    }</b>
<i>807</i>&nbsp;
<i>808</i>&nbsp;    /**
<i>809</i>&nbsp;     * Pushes the current best fitness value in a history queue.
<i>810</i>&nbsp;     *
<i>811</i>&nbsp;     * @param vals History queue.
<i>812</i>&nbsp;     * @param val Current best fitness value.
<i>813</i>&nbsp;     */
<i>814</i>&nbsp;    private static void push(double[] vals, double val) {
<b class="fc"><i>815</i>&nbsp;        for (int i = vals.length-1; i &gt; 0; i--) {</b>
<b class="fc"><i>816</i>&nbsp;            vals[i] = vals[i-1];</b>
<i>817</i>&nbsp;        }
<b class="fc"><i>818</i>&nbsp;        vals[0] = val;</b>
<b class="fc"><i>819</i>&nbsp;    }</b>
<i>820</i>&nbsp;
<i>821</i>&nbsp;    /**
<i>822</i>&nbsp;     * Sorts fitness values.
<i>823</i>&nbsp;     *
<i>824</i>&nbsp;     * @param doubles Array of values to be sorted.
<i>825</i>&nbsp;     * @return a sorted array of indices pointing into doubles.
<i>826</i>&nbsp;     */
<i>827</i>&nbsp;    private int[] sortedIndices(final double[] doubles) {
<b class="fc"><i>828</i>&nbsp;        final DoubleIndex[] dis = new DoubleIndex[doubles.length];</b>
<b class="fc"><i>829</i>&nbsp;        for (int i = 0; i &lt; doubles.length; i++) {</b>
<b class="fc"><i>830</i>&nbsp;            dis[i] = new DoubleIndex(doubles[i], i);</b>
<i>831</i>&nbsp;        }
<b class="fc"><i>832</i>&nbsp;        Arrays.sort(dis);</b>
<b class="fc"><i>833</i>&nbsp;        final int[] indices = new int[doubles.length];</b>
<b class="fc"><i>834</i>&nbsp;        for (int i = 0; i &lt; doubles.length; i++) {</b>
<b class="fc"><i>835</i>&nbsp;            indices[i] = dis[i].index;</b>
<i>836</i>&nbsp;        }
<b class="fc"><i>837</i>&nbsp;        return indices;</b>
<i>838</i>&nbsp;    }
<i>839</i>&nbsp;   /**
<i>840</i>&nbsp;     * Get range of values.
<i>841</i>&nbsp;     *
<i>842</i>&nbsp;     * @param vpPairs Array of valuePenaltyPairs to get range from.
<i>843</i>&nbsp;     * @return a double equal to maximum value minus minimum value.
<i>844</i>&nbsp;     */
<i>845</i>&nbsp;    private double valueRange(final ValuePenaltyPair[] vpPairs) {
<b class="fc"><i>846</i>&nbsp;        double max = Double.NEGATIVE_INFINITY;</b>
<b class="fc"><i>847</i>&nbsp;        double min = Double.MAX_VALUE;</b>
<b class="fc"><i>848</i>&nbsp;        for (ValuePenaltyPair vpPair:vpPairs) {</b>
<b class="fc"><i>849</i>&nbsp;            if (vpPair.value &gt; max) {</b>
<b class="fc"><i>850</i>&nbsp;                max = vpPair.value;</b>
<i>851</i>&nbsp;            }
<b class="fc"><i>852</i>&nbsp;            if (vpPair.value &lt; min) {</b>
<b class="fc"><i>853</i>&nbsp;                min = vpPair.value;</b>
<i>854</i>&nbsp;            }
<i>855</i>&nbsp;        }
<b class="fc"><i>856</i>&nbsp;        return max-min;</b>
<i>857</i>&nbsp;    }
<i>858</i>&nbsp;
<i>859</i>&nbsp;    /**
<i>860</i>&nbsp;     * Used to sort fitness values. Sorting is always in lower value first
<i>861</i>&nbsp;     * order.
<i>862</i>&nbsp;     */
<b class="fc"><i>863</i>&nbsp;    private static class DoubleIndex implements Comparable&lt;DoubleIndex&gt; {</b>
<i>864</i>&nbsp;        /** Value to compare. */
<i>865</i>&nbsp;        private final double value;
<i>866</i>&nbsp;        /** Index into sorted array. */
<i>867</i>&nbsp;        private final int index;
<i>868</i>&nbsp;
<i>869</i>&nbsp;        /**
<i>870</i>&nbsp;         * @param value Value to compare.
<i>871</i>&nbsp;         * @param index Index into sorted array.
<i>872</i>&nbsp;         */
<b class="fc"><i>873</i>&nbsp;        DoubleIndex(double value, int index) {</b>
<b class="fc"><i>874</i>&nbsp;            this.value = value;</b>
<b class="fc"><i>875</i>&nbsp;            this.index = index;</b>
<b class="fc"><i>876</i>&nbsp;        }</b>
<i>877</i>&nbsp;
<i>878</i>&nbsp;        /** {@inheritDoc} */
<i>879</i>&nbsp;        @Override
<i>880</i>&nbsp;        public int compareTo(DoubleIndex o) {
<b class="fc"><i>881</i>&nbsp;            return Double.compare(value, o.value);</b>
<i>882</i>&nbsp;        }
<i>883</i>&nbsp;
<i>884</i>&nbsp;        /** {@inheritDoc} */
<i>885</i>&nbsp;        @Override
<i>886</i>&nbsp;        public boolean equals(Object other) {
<i>887</i>&nbsp;
<b class="nc"><i>888</i>&nbsp;            if (this == other) {</b>
<b class="nc"><i>889</i>&nbsp;                return true;</b>
<i>890</i>&nbsp;            }
<i>891</i>&nbsp;
<b class="nc"><i>892</i>&nbsp;            if (other instanceof DoubleIndex) {</b>
<b class="nc"><i>893</i>&nbsp;                return Double.compare(value, ((DoubleIndex) other).value) == 0;</b>
<i>894</i>&nbsp;            }
<i>895</i>&nbsp;
<b class="nc"><i>896</i>&nbsp;            return false;</b>
<i>897</i>&nbsp;        }
<i>898</i>&nbsp;
<i>899</i>&nbsp;        /** {@inheritDoc} */
<i>900</i>&nbsp;        @Override
<i>901</i>&nbsp;        public int hashCode() {
<b class="nc"><i>902</i>&nbsp;            long bits = Double.doubleToLongBits(value);</b>
<b class="nc"><i>903</i>&nbsp;            return (int) ((1438542 ^ (bits &gt;&gt;&gt; 32) ^ bits) &amp; 0xffffffff);</b>
<i>904</i>&nbsp;        }
<i>905</i>&nbsp;    }
<i>906</i>&nbsp;    /**
<i>907</i>&nbsp;     * Stores the value and penalty (for repair of out of bounds point).
<i>908</i>&nbsp;     */
<b class="fc"><i>909</i>&nbsp;    private static class ValuePenaltyPair {</b>
<i>910</i>&nbsp;        /** Objective function value. */
<i>911</i>&nbsp;        private double value;
<i>912</i>&nbsp;        /** Penalty value for repair of out out of bounds points. */
<i>913</i>&nbsp;        private double penalty;
<i>914</i>&nbsp;
<i>915</i>&nbsp;        /**
<i>916</i>&nbsp;         * @param value Function value.
<i>917</i>&nbsp;         * @param penalty Out-of-bounds penalty.
<i>918</i>&nbsp;        */
<b class="fc"><i>919</i>&nbsp;        ValuePenaltyPair(final double value, final double penalty) {</b>
<b class="fc"><i>920</i>&nbsp;            this.value   = value;</b>
<b class="fc"><i>921</i>&nbsp;            this.penalty = penalty;</b>
<b class="fc"><i>922</i>&nbsp;        }</b>
<i>923</i>&nbsp;    }
<i>924</i>&nbsp;
<i>925</i>&nbsp;
<i>926</i>&nbsp;    /**
<i>927</i>&nbsp;     * Normalizes fitness values to the range [0,1]. Adds a penalty to the
<i>928</i>&nbsp;     * fitness value if out of range.
<i>929</i>&nbsp;     */
<b class="fc"><i>930</i>&nbsp;    private class FitnessFunction {</b>
<i>931</i>&nbsp;        /**
<i>932</i>&nbsp;         * Flag indicating whether the objective variables are forced into their
<i>933</i>&nbsp;         * bounds if defined
<i>934</i>&nbsp;         */
<i>935</i>&nbsp;        private final boolean isRepairMode;
<i>936</i>&nbsp;
<i>937</i>&nbsp;        /** Simple constructor.
<i>938</i>&nbsp;         */
<b class="fc"><i>939</i>&nbsp;        FitnessFunction() {</b>
<b class="fc"><i>940</i>&nbsp;            isRepairMode = true;</b>
<b class="fc"><i>941</i>&nbsp;        }</b>
<i>942</i>&nbsp;
<i>943</i>&nbsp;        /**
<i>944</i>&nbsp;         * @param point Normalized objective variables.
<i>945</i>&nbsp;         * @return the objective value + penalty for violated bounds.
<i>946</i>&nbsp;         */
<i>947</i>&nbsp;        public ValuePenaltyPair value(final double[] point) {
<i>948</i>&nbsp;            double value;
<b class="fc"><i>949</i>&nbsp;            double penalty=0.0;</b>
<b class="fc"><i>950</i>&nbsp;            if (isRepairMode) {</b>
<b class="fc"><i>951</i>&nbsp;                double[] repaired = repair(point);</b>
<b class="fc"><i>952</i>&nbsp;                value = CMAESOptimizer.this.computeObjectiveValue(repaired);</b>
<b class="fc"><i>953</i>&nbsp;                penalty =  penalty(point, repaired);</b>
<b class="fc"><i>954</i>&nbsp;            } else {</b>
<b class="nc"><i>955</i>&nbsp;                value = CMAESOptimizer.this.computeObjectiveValue(point);</b>
<i>956</i>&nbsp;            }
<b class="fc"><i>957</i>&nbsp;            value = isMinimize ? value : -value;</b>
<b class="fc"><i>958</i>&nbsp;            penalty = isMinimize ? penalty : -penalty;</b>
<b class="fc"><i>959</i>&nbsp;            return new ValuePenaltyPair(value,penalty);</b>
<i>960</i>&nbsp;        }
<i>961</i>&nbsp;
<i>962</i>&nbsp;        /**
<i>963</i>&nbsp;         * @param x Normalized objective variables.
<i>964</i>&nbsp;         * @return {@code true} if in bounds.
<i>965</i>&nbsp;         */
<i>966</i>&nbsp;        public boolean isFeasible(final double[] x) {
<b class="nc"><i>967</i>&nbsp;            final double[] lB = CMAESOptimizer.this.getLowerBound();</b>
<b class="nc"><i>968</i>&nbsp;            final double[] uB = CMAESOptimizer.this.getUpperBound();</b>
<i>969</i>&nbsp;
<b class="nc"><i>970</i>&nbsp;            for (int i = 0; i &lt; x.length; i++) {</b>
<b class="nc"><i>971</i>&nbsp;                if (x[i] &lt; lB[i]) {</b>
<b class="nc"><i>972</i>&nbsp;                    return false;</b>
<i>973</i>&nbsp;                }
<b class="nc"><i>974</i>&nbsp;                if (x[i] &gt; uB[i]) {</b>
<b class="nc"><i>975</i>&nbsp;                    return false;</b>
<i>976</i>&nbsp;                }
<i>977</i>&nbsp;            }
<b class="nc"><i>978</i>&nbsp;            return true;</b>
<i>979</i>&nbsp;        }
<i>980</i>&nbsp;
<i>981</i>&nbsp;        /**
<i>982</i>&nbsp;         * @param x Normalized objective variables.
<i>983</i>&nbsp;         * @return the repaired (i.e. all in bounds) objective variables.
<i>984</i>&nbsp;         */
<i>985</i>&nbsp;        private double[] repair(final double[] x) {
<b class="fc"><i>986</i>&nbsp;            final double[] lB = CMAESOptimizer.this.getLowerBound();</b>
<b class="fc"><i>987</i>&nbsp;            final double[] uB = CMAESOptimizer.this.getUpperBound();</b>
<i>988</i>&nbsp;
<b class="fc"><i>989</i>&nbsp;            final double[] repaired = new double[x.length];</b>
<b class="fc"><i>990</i>&nbsp;            for (int i = 0; i &lt; x.length; i++) {</b>
<b class="fc"><i>991</i>&nbsp;                if (x[i] &lt; lB[i]) {</b>
<b class="nc"><i>992</i>&nbsp;                    repaired[i] = lB[i];</b>
<b class="fc"><i>993</i>&nbsp;                } else if (x[i] &gt; uB[i]) {</b>
<b class="fc"><i>994</i>&nbsp;                    repaired[i] = uB[i];</b>
<i>995</i>&nbsp;                } else {
<b class="fc"><i>996</i>&nbsp;                    repaired[i] = x[i];</b>
<i>997</i>&nbsp;                }
<i>998</i>&nbsp;            }
<b class="fc"><i>999</i>&nbsp;            return repaired;</b>
<i>1000</i>&nbsp;        }
<i>1001</i>&nbsp;
<i>1002</i>&nbsp;        /**
<i>1003</i>&nbsp;         * @param x Normalized objective variables.
<i>1004</i>&nbsp;         * @param repaired Repaired objective variables.
<i>1005</i>&nbsp;         * @return Penalty value according to the violation of the bounds.
<i>1006</i>&nbsp;         */
<i>1007</i>&nbsp;        private double penalty(final double[] x, final double[] repaired) {
<b class="fc"><i>1008</i>&nbsp;            double penalty = 0;</b>
<b class="fc"><i>1009</i>&nbsp;            for (int i = 0; i &lt; x.length; i++) {</b>
<b class="fc"><i>1010</i>&nbsp;                double diff = FastMath.abs(x[i] - repaired[i]);</b>
<b class="fc"><i>1011</i>&nbsp;                penalty += diff;</b>
<i>1012</i>&nbsp;            }
<b class="fc"><i>1013</i>&nbsp;            return isMinimize ? penalty : -penalty;</b>
<i>1014</i>&nbsp;        }
<i>1015</i>&nbsp;    }
<i>1016</i>&nbsp;
<i>1017</i>&nbsp;    // -----Matrix utility functions similar to the Matlab build in functions------
<i>1018</i>&nbsp;
<i>1019</i>&nbsp;    /**
<i>1020</i>&nbsp;     * @param m Input matrix
<i>1021</i>&nbsp;     * @return Matrix representing the element-wise logarithm of m.
<i>1022</i>&nbsp;     */
<i>1023</i>&nbsp;    private static RealMatrix log(final RealMatrix m) {
<b class="fc"><i>1024</i>&nbsp;        final double[][] d = new double[m.getRowDimension()][m.getColumnDimension()];</b>
<b class="fc"><i>1025</i>&nbsp;        for (int r = 0; r &lt; m.getRowDimension(); r++) {</b>
<b class="fc"><i>1026</i>&nbsp;            for (int c = 0; c &lt; m.getColumnDimension(); c++) {</b>
<b class="fc"><i>1027</i>&nbsp;                d[r][c] = FastMath.log(m.getEntry(r, c));</b>
<i>1028</i>&nbsp;            }
<i>1029</i>&nbsp;        }
<b class="fc"><i>1030</i>&nbsp;        return new Array2DRowRealMatrix(d, false);</b>
<i>1031</i>&nbsp;    }
<i>1032</i>&nbsp;
<i>1033</i>&nbsp;    /**
<i>1034</i>&nbsp;     * @param m Input matrix.
<i>1035</i>&nbsp;     * @return Matrix representing the element-wise square root of m.
<i>1036</i>&nbsp;     */
<i>1037</i>&nbsp;    private static RealMatrix sqrt(final RealMatrix m) {
<b class="fc"><i>1038</i>&nbsp;        final double[][] d = new double[m.getRowDimension()][m.getColumnDimension()];</b>
<b class="fc"><i>1039</i>&nbsp;        for (int r = 0; r &lt; m.getRowDimension(); r++) {</b>
<b class="fc"><i>1040</i>&nbsp;            for (int c = 0; c &lt; m.getColumnDimension(); c++) {</b>
<b class="fc"><i>1041</i>&nbsp;                d[r][c] = FastMath.sqrt(m.getEntry(r, c));</b>
<i>1042</i>&nbsp;            }
<i>1043</i>&nbsp;        }
<b class="fc"><i>1044</i>&nbsp;        return new Array2DRowRealMatrix(d, false);</b>
<i>1045</i>&nbsp;    }
<i>1046</i>&nbsp;
<i>1047</i>&nbsp;    /**
<i>1048</i>&nbsp;     * @param m Input matrix.
<i>1049</i>&nbsp;     * @return Matrix representing the element-wise square of m.
<i>1050</i>&nbsp;     */
<i>1051</i>&nbsp;    private static RealMatrix square(final RealMatrix m) {
<b class="fc"><i>1052</i>&nbsp;        final double[][] d = new double[m.getRowDimension()][m.getColumnDimension()];</b>
<b class="fc"><i>1053</i>&nbsp;        for (int r = 0; r &lt; m.getRowDimension(); r++) {</b>
<b class="fc"><i>1054</i>&nbsp;            for (int c = 0; c &lt; m.getColumnDimension(); c++) {</b>
<b class="fc"><i>1055</i>&nbsp;                double e = m.getEntry(r, c);</b>
<b class="fc"><i>1056</i>&nbsp;                d[r][c] = e * e;</b>
<i>1057</i>&nbsp;            }
<i>1058</i>&nbsp;        }
<b class="fc"><i>1059</i>&nbsp;        return new Array2DRowRealMatrix(d, false);</b>
<i>1060</i>&nbsp;    }
<i>1061</i>&nbsp;
<i>1062</i>&nbsp;    /**
<i>1063</i>&nbsp;     * @param m Input matrix 1.
<i>1064</i>&nbsp;     * @param n Input matrix 2.
<i>1065</i>&nbsp;     * @return the matrix where the elements of m and n are element-wise multiplied.
<i>1066</i>&nbsp;     */
<i>1067</i>&nbsp;    private static RealMatrix times(final RealMatrix m, final RealMatrix n) {
<b class="fc"><i>1068</i>&nbsp;        final double[][] d = new double[m.getRowDimension()][m.getColumnDimension()];</b>
<b class="fc"><i>1069</i>&nbsp;        for (int r = 0; r &lt; m.getRowDimension(); r++) {</b>
<b class="fc"><i>1070</i>&nbsp;            for (int c = 0; c &lt; m.getColumnDimension(); c++) {</b>
<b class="fc"><i>1071</i>&nbsp;                d[r][c] = m.getEntry(r, c) * n.getEntry(r, c);</b>
<i>1072</i>&nbsp;            }
<i>1073</i>&nbsp;        }
<b class="fc"><i>1074</i>&nbsp;        return new Array2DRowRealMatrix(d, false);</b>
<i>1075</i>&nbsp;    }
<i>1076</i>&nbsp;
<i>1077</i>&nbsp;    /**
<i>1078</i>&nbsp;     * @param m Input matrix 1.
<i>1079</i>&nbsp;     * @param n Input matrix 2.
<i>1080</i>&nbsp;     * @return Matrix where the elements of m and n are element-wise divided.
<i>1081</i>&nbsp;     */
<i>1082</i>&nbsp;    private static RealMatrix divide(final RealMatrix m, final RealMatrix n) {
<b class="fc"><i>1083</i>&nbsp;        final double[][] d = new double[m.getRowDimension()][m.getColumnDimension()];</b>
<b class="fc"><i>1084</i>&nbsp;        for (int r = 0; r &lt; m.getRowDimension(); r++) {</b>
<b class="fc"><i>1085</i>&nbsp;            for (int c = 0; c &lt; m.getColumnDimension(); c++) {</b>
<b class="fc"><i>1086</i>&nbsp;                d[r][c] = m.getEntry(r, c) / n.getEntry(r, c);</b>
<i>1087</i>&nbsp;            }
<i>1088</i>&nbsp;        }
<b class="fc"><i>1089</i>&nbsp;        return new Array2DRowRealMatrix(d, false);</b>
<i>1090</i>&nbsp;    }
<i>1091</i>&nbsp;
<i>1092</i>&nbsp;    /**
<i>1093</i>&nbsp;     * @param m Input matrix.
<i>1094</i>&nbsp;     * @param cols Columns to select.
<i>1095</i>&nbsp;     * @return Matrix representing the selected columns.
<i>1096</i>&nbsp;     */
<i>1097</i>&nbsp;    private static RealMatrix selectColumns(final RealMatrix m, final int[] cols) {
<b class="fc"><i>1098</i>&nbsp;        final double[][] d = new double[m.getRowDimension()][cols.length];</b>
<b class="fc"><i>1099</i>&nbsp;        for (int r = 0; r &lt; m.getRowDimension(); r++) {</b>
<b class="fc"><i>1100</i>&nbsp;            for (int c = 0; c &lt; cols.length; c++) {</b>
<b class="fc"><i>1101</i>&nbsp;                d[r][c] = m.getEntry(r, cols[c]);</b>
<i>1102</i>&nbsp;            }
<i>1103</i>&nbsp;        }
<b class="fc"><i>1104</i>&nbsp;        return new Array2DRowRealMatrix(d, false);</b>
<i>1105</i>&nbsp;    }
<i>1106</i>&nbsp;
<i>1107</i>&nbsp;    /**
<i>1108</i>&nbsp;     * @param m Input matrix.
<i>1109</i>&nbsp;     * @param k Diagonal position.
<i>1110</i>&nbsp;     * @return Upper triangular part of matrix.
<i>1111</i>&nbsp;     */
<i>1112</i>&nbsp;    private static RealMatrix triu(final RealMatrix m, int k) {
<b class="fc"><i>1113</i>&nbsp;        final double[][] d = new double[m.getRowDimension()][m.getColumnDimension()];</b>
<b class="fc"><i>1114</i>&nbsp;        for (int r = 0; r &lt; m.getRowDimension(); r++) {</b>
<b class="fc"><i>1115</i>&nbsp;            for (int c = 0; c &lt; m.getColumnDimension(); c++) {</b>
<b class="fc"><i>1116</i>&nbsp;                d[r][c] = r &lt;= c - k ? m.getEntry(r, c) : 0;</b>
<i>1117</i>&nbsp;            }
<i>1118</i>&nbsp;        }
<b class="fc"><i>1119</i>&nbsp;        return new Array2DRowRealMatrix(d, false);</b>
<i>1120</i>&nbsp;    }
<i>1121</i>&nbsp;
<i>1122</i>&nbsp;    /**
<i>1123</i>&nbsp;     * @param m Input matrix.
<i>1124</i>&nbsp;     * @return Row matrix representing the sums of the rows.
<i>1125</i>&nbsp;     */
<i>1126</i>&nbsp;    private static RealMatrix sumRows(final RealMatrix m) {
<b class="fc"><i>1127</i>&nbsp;        final double[][] d = new double[1][m.getColumnDimension()];</b>
<b class="fc"><i>1128</i>&nbsp;        for (int c = 0; c &lt; m.getColumnDimension(); c++) {</b>
<b class="fc"><i>1129</i>&nbsp;            double sum = 0;</b>
<b class="fc"><i>1130</i>&nbsp;            for (int r = 0; r &lt; m.getRowDimension(); r++) {</b>
<b class="fc"><i>1131</i>&nbsp;                sum += m.getEntry(r, c);</b>
<i>1132</i>&nbsp;            }
<b class="fc"><i>1133</i>&nbsp;            d[0][c] = sum;</b>
<i>1134</i>&nbsp;        }
<b class="fc"><i>1135</i>&nbsp;        return new Array2DRowRealMatrix(d, false);</b>
<i>1136</i>&nbsp;    }
<i>1137</i>&nbsp;
<i>1138</i>&nbsp;    /**
<i>1139</i>&nbsp;     * @param m Input matrix.
<i>1140</i>&nbsp;     * @return the diagonal n-by-n matrix if m is a column matrix or the column
<i>1141</i>&nbsp;     * matrix representing the diagonal if m is a n-by-n matrix.
<i>1142</i>&nbsp;     */
<i>1143</i>&nbsp;    private static RealMatrix diag(final RealMatrix m) {
<b class="fc"><i>1144</i>&nbsp;        if (m.getColumnDimension() == 1) {</b>
<b class="fc"><i>1145</i>&nbsp;            final double[][] d = new double[m.getRowDimension()][m.getRowDimension()];</b>
<b class="fc"><i>1146</i>&nbsp;            for (int i = 0; i &lt; m.getRowDimension(); i++) {</b>
<b class="fc"><i>1147</i>&nbsp;                d[i][i] = m.getEntry(i, 0);</b>
<i>1148</i>&nbsp;            }
<b class="fc"><i>1149</i>&nbsp;            return new Array2DRowRealMatrix(d, false);</b>
<i>1150</i>&nbsp;        } else {
<b class="fc"><i>1151</i>&nbsp;            final double[][] d = new double[m.getRowDimension()][1];</b>
<b class="fc"><i>1152</i>&nbsp;            for (int i = 0; i &lt; m.getColumnDimension(); i++) {</b>
<b class="fc"><i>1153</i>&nbsp;                d[i][0] = m.getEntry(i, i);</b>
<i>1154</i>&nbsp;            }
<b class="fc"><i>1155</i>&nbsp;            return new Array2DRowRealMatrix(d, false);</b>
<i>1156</i>&nbsp;        }
<i>1157</i>&nbsp;    }
<i>1158</i>&nbsp;
<i>1159</i>&nbsp;    /**
<i>1160</i>&nbsp;     * Copies a column from m1 to m2.
<i>1161</i>&nbsp;     *
<i>1162</i>&nbsp;     * @param m1 Source matrix.
<i>1163</i>&nbsp;     * @param col1 Source column.
<i>1164</i>&nbsp;     * @param m2 Target matrix.
<i>1165</i>&nbsp;     * @param col2 Target column.
<i>1166</i>&nbsp;     */
<i>1167</i>&nbsp;    private static void copyColumn(final RealMatrix m1, int col1,
<i>1168</i>&nbsp;                                   RealMatrix m2, int col2) {
<b class="fc"><i>1169</i>&nbsp;        for (int i = 0; i &lt; m1.getRowDimension(); i++) {</b>
<b class="fc"><i>1170</i>&nbsp;            m2.setEntry(i, col2, m1.getEntry(i, col1));</b>
<i>1171</i>&nbsp;        }
<b class="fc"><i>1172</i>&nbsp;    }</b>
<i>1173</i>&nbsp;
<i>1174</i>&nbsp;    /**
<i>1175</i>&nbsp;     * @param n Number of rows.
<i>1176</i>&nbsp;     * @param m Number of columns.
<i>1177</i>&nbsp;     * @return n-by-m matrix filled with 1.
<i>1178</i>&nbsp;     */
<i>1179</i>&nbsp;    private static RealMatrix ones(int n, int m) {
<b class="fc"><i>1180</i>&nbsp;        final double[][] d = new double[n][m];</b>
<b class="fc"><i>1181</i>&nbsp;        for (int r = 0; r &lt; n; r++) {</b>
<b class="fc"><i>1182</i>&nbsp;            Arrays.fill(d[r], 1);</b>
<i>1183</i>&nbsp;        }
<b class="fc"><i>1184</i>&nbsp;        return new Array2DRowRealMatrix(d, false);</b>
<i>1185</i>&nbsp;    }
<i>1186</i>&nbsp;
<i>1187</i>&nbsp;    /**
<i>1188</i>&nbsp;     * @param n Number of rows.
<i>1189</i>&nbsp;     * @param m Number of columns.
<i>1190</i>&nbsp;     * @return n-by-m matrix of 0 values out of diagonal, and 1 values on
<i>1191</i>&nbsp;     * the diagonal.
<i>1192</i>&nbsp;     */
<i>1193</i>&nbsp;    private static RealMatrix eye(int n, int m) {
<b class="fc"><i>1194</i>&nbsp;        final double[][] d = new double[n][m];</b>
<b class="fc"><i>1195</i>&nbsp;        for (int r = 0; r &lt; n; r++) {</b>
<b class="fc"><i>1196</i>&nbsp;            if (r &lt; m) {</b>
<b class="fc"><i>1197</i>&nbsp;                d[r][r] = 1;</b>
<i>1198</i>&nbsp;            }
<i>1199</i>&nbsp;        }
<b class="fc"><i>1200</i>&nbsp;        return new Array2DRowRealMatrix(d, false);</b>
<i>1201</i>&nbsp;    }
<i>1202</i>&nbsp;
<i>1203</i>&nbsp;    /**
<i>1204</i>&nbsp;     * @param n Number of rows.
<i>1205</i>&nbsp;     * @param m Number of columns.
<i>1206</i>&nbsp;     * @return n-by-m matrix of zero values.
<i>1207</i>&nbsp;     */
<i>1208</i>&nbsp;    private static RealMatrix zeros(int n, int m) {
<b class="fc"><i>1209</i>&nbsp;        return new Array2DRowRealMatrix(n, m);</b>
<i>1210</i>&nbsp;    }
<i>1211</i>&nbsp;
<i>1212</i>&nbsp;    /**
<i>1213</i>&nbsp;     * @param mat Input matrix.
<i>1214</i>&nbsp;     * @param n Number of row replicates.
<i>1215</i>&nbsp;     * @param m Number of column replicates.
<i>1216</i>&nbsp;     * @return a matrix which replicates the input matrix in both directions.
<i>1217</i>&nbsp;     */
<i>1218</i>&nbsp;    private static RealMatrix repmat(final RealMatrix mat, int n, int m) {
<b class="fc"><i>1219</i>&nbsp;        final int rd = mat.getRowDimension();</b>
<b class="fc"><i>1220</i>&nbsp;        final int cd = mat.getColumnDimension();</b>
<b class="fc"><i>1221</i>&nbsp;        final double[][] d = new double[n * rd][m * cd];</b>
<b class="fc"><i>1222</i>&nbsp;        for (int r = 0; r &lt; n * rd; r++) {</b>
<b class="fc"><i>1223</i>&nbsp;            for (int c = 0; c &lt; m * cd; c++) {</b>
<b class="fc"><i>1224</i>&nbsp;                d[r][c] = mat.getEntry(r % rd, c % cd);</b>
<i>1225</i>&nbsp;            }
<i>1226</i>&nbsp;        }
<b class="fc"><i>1227</i>&nbsp;        return new Array2DRowRealMatrix(d, false);</b>
<i>1228</i>&nbsp;    }
<i>1229</i>&nbsp;
<i>1230</i>&nbsp;    /**
<i>1231</i>&nbsp;     * @param start Start value.
<i>1232</i>&nbsp;     * @param end End value.
<i>1233</i>&nbsp;     * @param step Step size.
<i>1234</i>&nbsp;     * @return a sequence as column matrix.
<i>1235</i>&nbsp;     */
<i>1236</i>&nbsp;    private static RealMatrix sequence(double start, double end, double step) {
<b class="fc"><i>1237</i>&nbsp;        final int size = (int) ((end - start) / step + 1);</b>
<b class="fc"><i>1238</i>&nbsp;        final double[][] d = new double[size][1];</b>
<b class="fc"><i>1239</i>&nbsp;        double value = start;</b>
<b class="fc"><i>1240</i>&nbsp;        for (int r = 0; r &lt; size; r++) {</b>
<b class="fc"><i>1241</i>&nbsp;            d[r][0] = value;</b>
<b class="fc"><i>1242</i>&nbsp;            value += step;</b>
<i>1243</i>&nbsp;        }
<b class="fc"><i>1244</i>&nbsp;        return new Array2DRowRealMatrix(d, false);</b>
<i>1245</i>&nbsp;    }
<i>1246</i>&nbsp;
<i>1247</i>&nbsp;    /**
<i>1248</i>&nbsp;     * @param m Input matrix.
<i>1249</i>&nbsp;     * @return the maximum of the matrix element values.
<i>1250</i>&nbsp;     */
<i>1251</i>&nbsp;    private static double max(final RealMatrix m) {
<b class="fc"><i>1252</i>&nbsp;        double max = -Double.MAX_VALUE;</b>
<b class="fc"><i>1253</i>&nbsp;        for (int r = 0; r &lt; m.getRowDimension(); r++) {</b>
<b class="fc"><i>1254</i>&nbsp;            for (int c = 0; c &lt; m.getColumnDimension(); c++) {</b>
<b class="fc"><i>1255</i>&nbsp;                double e = m.getEntry(r, c);</b>
<b class="fc"><i>1256</i>&nbsp;                if (max &lt; e) {</b>
<b class="fc"><i>1257</i>&nbsp;                    max = e;</b>
<i>1258</i>&nbsp;                }
<i>1259</i>&nbsp;            }
<i>1260</i>&nbsp;        }
<b class="fc"><i>1261</i>&nbsp;        return max;</b>
<i>1262</i>&nbsp;    }
<i>1263</i>&nbsp;
<i>1264</i>&nbsp;    /**
<i>1265</i>&nbsp;     * @param m Input matrix.
<i>1266</i>&nbsp;     * @return the minimum of the matrix element values.
<i>1267</i>&nbsp;     */
<i>1268</i>&nbsp;    private static double min(final RealMatrix m) {
<b class="fc"><i>1269</i>&nbsp;        double min = Double.MAX_VALUE;</b>
<b class="fc"><i>1270</i>&nbsp;        for (int r = 0; r &lt; m.getRowDimension(); r++) {</b>
<b class="fc"><i>1271</i>&nbsp;            for (int c = 0; c &lt; m.getColumnDimension(); c++) {</b>
<b class="fc"><i>1272</i>&nbsp;                double e = m.getEntry(r, c);</b>
<b class="fc"><i>1273</i>&nbsp;                if (min &gt; e) {</b>
<b class="fc"><i>1274</i>&nbsp;                    min = e;</b>
<i>1275</i>&nbsp;                }
<i>1276</i>&nbsp;            }
<i>1277</i>&nbsp;        }
<b class="fc"><i>1278</i>&nbsp;        return min;</b>
<i>1279</i>&nbsp;    }
<i>1280</i>&nbsp;
<i>1281</i>&nbsp;    /**
<i>1282</i>&nbsp;     * @param m Input array.
<i>1283</i>&nbsp;     * @return the maximum of the array values.
<i>1284</i>&nbsp;     */
<i>1285</i>&nbsp;    private static double max(final double[] m) {
<b class="fc"><i>1286</i>&nbsp;        double max = -Double.MAX_VALUE;</b>
<b class="fc"><i>1287</i>&nbsp;        for (int r = 0; r &lt; m.length; r++) {</b>
<b class="fc"><i>1288</i>&nbsp;            if (max &lt; m[r]) {</b>
<b class="fc"><i>1289</i>&nbsp;                max = m[r];</b>
<i>1290</i>&nbsp;            }
<i>1291</i>&nbsp;        }
<b class="fc"><i>1292</i>&nbsp;        return max;</b>
<i>1293</i>&nbsp;    }
<i>1294</i>&nbsp;
<i>1295</i>&nbsp;    /**
<i>1296</i>&nbsp;     * @param m Input array.
<i>1297</i>&nbsp;     * @return the minimum of the array values.
<i>1298</i>&nbsp;     */
<i>1299</i>&nbsp;    private static double min(final double[] m) {
<b class="fc"><i>1300</i>&nbsp;        double min = Double.MAX_VALUE;</b>
<b class="fc"><i>1301</i>&nbsp;        for (int r = 0; r &lt; m.length; r++) {</b>
<b class="fc"><i>1302</i>&nbsp;            if (min &gt; m[r]) {</b>
<b class="fc"><i>1303</i>&nbsp;                min = m[r];</b>
<i>1304</i>&nbsp;            }
<i>1305</i>&nbsp;        }
<b class="fc"><i>1306</i>&nbsp;        return min;</b>
<i>1307</i>&nbsp;    }
<i>1308</i>&nbsp;
<i>1309</i>&nbsp;    /**
<i>1310</i>&nbsp;     * @param indices Input index array.
<i>1311</i>&nbsp;     * @return the inverse of the mapping defined by indices.
<i>1312</i>&nbsp;     */
<i>1313</i>&nbsp;    private static int[] inverse(final int[] indices) {
<b class="fc"><i>1314</i>&nbsp;        final int[] inverse = new int[indices.length];</b>
<b class="fc"><i>1315</i>&nbsp;        for (int i = 0; i &lt; indices.length; i++) {</b>
<b class="fc"><i>1316</i>&nbsp;            inverse[indices[i]] = i;</b>
<i>1317</i>&nbsp;        }
<b class="fc"><i>1318</i>&nbsp;        return inverse;</b>
<i>1319</i>&nbsp;    }
<i>1320</i>&nbsp;
<i>1321</i>&nbsp;    /**
<i>1322</i>&nbsp;     * @param indices Input index array.
<i>1323</i>&nbsp;     * @return the indices in inverse order (last is first).
<i>1324</i>&nbsp;     */
<i>1325</i>&nbsp;    private static int[] reverse(final int[] indices) {
<b class="fc"><i>1326</i>&nbsp;        final int[] reverse = new int[indices.length];</b>
<b class="fc"><i>1327</i>&nbsp;        for (int i = 0; i &lt; indices.length; i++) {</b>
<b class="fc"><i>1328</i>&nbsp;            reverse[i] = indices[indices.length - i - 1];</b>
<i>1329</i>&nbsp;        }
<b class="fc"><i>1330</i>&nbsp;        return reverse;</b>
<i>1331</i>&nbsp;    }
<i>1332</i>&nbsp;
<i>1333</i>&nbsp;    /**
<i>1334</i>&nbsp;     * @param size Length of random array.
<i>1335</i>&nbsp;     * @return an array of Gaussian random numbers.
<i>1336</i>&nbsp;     */
<i>1337</i>&nbsp;    private double[] randn(int size) {
<b class="nc"><i>1338</i>&nbsp;        final double[] randn = new double[size];</b>
<b class="nc"><i>1339</i>&nbsp;        for (int i = 0; i &lt; size; i++) {</b>
<b class="nc"><i>1340</i>&nbsp;            randn[i] = random.sample();</b>
<i>1341</i>&nbsp;        }
<b class="nc"><i>1342</i>&nbsp;        return randn;</b>
<i>1343</i>&nbsp;    }
<i>1344</i>&nbsp;
<i>1345</i>&nbsp;    /**
<i>1346</i>&nbsp;     * @param size Number of rows.
<i>1347</i>&nbsp;     * @param popSize Population size.
<i>1348</i>&nbsp;     * @return a 2-dimensional matrix of Gaussian random numbers.
<i>1349</i>&nbsp;     */
<i>1350</i>&nbsp;    private RealMatrix randn1(int size, int popSize) {
<b class="fc"><i>1351</i>&nbsp;        final double[][] d = new double[size][popSize];</b>
<b class="fc"><i>1352</i>&nbsp;        for (int r = 0; r &lt; size; r++) {</b>
<b class="fc"><i>1353</i>&nbsp;            for (int c = 0; c &lt; popSize; c++) {</b>
<b class="fc"><i>1354</i>&nbsp;                d[r][c] = random.sample();</b>
<i>1355</i>&nbsp;            }
<i>1356</i>&nbsp;        }
<b class="fc"><i>1357</i>&nbsp;        return new Array2DRowRealMatrix(d, false);</b>
<i>1358</i>&nbsp;    }
<i>1359</i>&nbsp;}
</div>
</div>

<div class="footer">
    
    <div style="float:right;">generated on 2019-06-04 09:26</div>
</div>
</body>
</html>
